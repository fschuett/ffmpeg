package org.ffmpeg.avformat;
import org.bridj.BridJ;
import org.bridj.Callback;
import org.bridj.IntValuedEnum;
import org.bridj.Pointer;
import org.bridj.StructObject;
import org.bridj.ann.Array;
import org.bridj.ann.Field;
import org.bridj.ann.Library;
import org.bridj.ann.Struct;
import org.bridj.ann.Ptr;
import org.bridj.util.DefaultParameterizedType;
import org.ffmpeg.avcodec.AVCodec;
import org.ffmpeg.avcodec.AvcodecLibrary.AVCodecID;
import org.ffmpeg.avformat.AvformatLibrary.AVDurationEstimationMethod;
import org.ffmpeg.avformat.AvformatLibrary.av_format_control_message;
import org.ffmpeg.avutil.AVClass;
import org.ffmpeg.avutil.AVDictionary;
import org.ffmpeg.util.AlignmentCustomizer;

/**
 * <i>native declaration : libavformat/avformat.h:1055</i><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> or <a href="http://bridj.googlecode.com/">BridJ</a> .
 */
@Library("avformat") 
public class AVFormatContext extends StructObject {
	static {
		BridJ.register();
	}
	/**
	 * A class for logging and @ref avoptions. Set by avformat_alloc_context().<br>
	 * Exports (de)muxer private options if they exist.<br>
	 * C type : const AVClass*
	 */
	@Field(0) 
	public Pointer<AVClass > av_class() {
		return this.io.getPointerField(this, 0);
	}
	/**
	 * A class for logging and @ref avoptions. Set by avformat_alloc_context().<br>
	 * Exports (de)muxer private options if they exist.<br>
	 * C type : const AVClass*
	 */
	@Field(0) 
	public AVFormatContext av_class(Pointer<AVClass > av_class) {
		this.io.setPointerField(this, 0, av_class);
		return this;
	}
	/**
	 * The input container format.<br>
	 * * Demuxing only, set by avformat_open_input().<br>
	 * C type : AVInputFormat*
	 */
	@Field(1) 
	public Pointer<AVInputFormat > iformat() {
		return this.io.getPointerField(this, 1);
	}
	/**
	 * The input container format.<br>
	 * * Demuxing only, set by avformat_open_input().<br>
	 * C type : AVInputFormat*
	 */
	@Field(1) 
	public AVFormatContext iformat(Pointer<AVInputFormat > iformat) {
		this.io.setPointerField(this, 1, iformat);
		return this;
	}
	/**
	 * The output container format.<br>
	 * * Muxing only, must be set by the caller before avformat_write_header().<br>
	 * C type : AVOutputFormat*
	 */
	@Field(2) 
	public Pointer<AVOutputFormat > oformat() {
		return this.io.getPointerField(this, 2);
	}
	/**
	 * The output container format.<br>
	 * * Muxing only, must be set by the caller before avformat_write_header().<br>
	 * C type : AVOutputFormat*
	 */
	@Field(2) 
	public AVFormatContext oformat(Pointer<AVOutputFormat > oformat) {
		this.io.setPointerField(this, 2, oformat);
		return this;
	}
	/**
	 * Format private data. This is an AVOptions-enabled struct<br>
	 * if and only if iformat/oformat.priv_class is not NULL.<br>
	 * * - muxing: set by avformat_write_header()<br>
	 * - demuxing: set by avformat_open_input()<br>
	 * C type : void*
	 */
	@Field(3) 
	public Pointer<? > priv_data() {
		return this.io.getPointerField(this, 3);
	}
	/**
	 * Format private data. This is an AVOptions-enabled struct<br>
	 * if and only if iformat/oformat.priv_class is not NULL.<br>
	 * * - muxing: set by avformat_write_header()<br>
	 * - demuxing: set by avformat_open_input()<br>
	 * C type : void*
	 */
	@Field(3) 
	public AVFormatContext priv_data(Pointer<? > priv_data) {
		this.io.setPointerField(this, 3, priv_data);
		return this;
	}
	/**
	 * I/O context.<br>
	 * * - demuxing: either set by the user before avformat_open_input() (then<br>
	 *             the user must close it manually) or set by avformat_open_input().<br>
	 * - muxing: set by the user before avformat_write_header(). The caller must<br>
	 *           take care of closing / freeing the IO context.<br>
	 * * Do NOT set this field if AVFMT_NOFILE flag is set in<br>
	 * iformat/oformat.flags. In such a case, the (de)muxer will handle<br>
	 * I/O in some other way and this field will be NULL.<br>
	 * C type : AVIOContext*
	 */
	@Field(4) 
	public Pointer<AVIOContext > pb() {
		return this.io.getPointerField(this, 4);
	}
	/**
	 * I/O context.<br>
	 * * - demuxing: either set by the user before avformat_open_input() (then<br>
	 *             the user must close it manually) or set by avformat_open_input().<br>
	 * - muxing: set by the user before avformat_write_header(). The caller must<br>
	 *           take care of closing / freeing the IO context.<br>
	 * * Do NOT set this field if AVFMT_NOFILE flag is set in<br>
	 * iformat/oformat.flags. In such a case, the (de)muxer will handle<br>
	 * I/O in some other way and this field will be NULL.<br>
	 * C type : AVIOContext*
	 */
	@Field(4) 
	public AVFormatContext pb(Pointer<AVIOContext > pb) {
		this.io.setPointerField(this, 4, pb);
		return this;
	}
	/**
	 * Flags signalling stream properties. A combination of AVFMTCTX_*.<br>
	 * Set by libavformat.
	 */
	@Field(5) 
	public int ctx_flags() {
		return this.io.getIntField(this, 5);
	}
	/**
	 * Flags signalling stream properties. A combination of AVFMTCTX_*.<br>
	 * Set by libavformat.
	 */
	@Field(5) 
	public AVFormatContext ctx_flags(int ctx_flags) {
		this.io.setIntField(this, 5, ctx_flags);
		return this;
	}
	/**
	 * Number of elements in AVFormatContext.streams.<br>
	 * * Set by avformat_new_stream(), must not be modified by any other code.
	 */
	@Field(6) 
	public int nb_streams() {
		return this.io.getIntField(this, 6);
	}
	/**
	 * Number of elements in AVFormatContext.streams.<br>
	 * * Set by avformat_new_stream(), must not be modified by any other code.
	 */
	@Field(6) 
	public AVFormatContext nb_streams(int nb_streams) {
		this.io.setIntField(this, 6, nb_streams);
		return this;
	}
	/**
	 * A list of all streams in the file. New streams are created with<br>
	 * avformat_new_stream().<br>
	 * * - demuxing: streams are created by libavformat in avformat_open_input().<br>
	 *             If AVFMTCTX_NOHEADER is set in ctx_flags, then new streams may also<br>
	 *             appear in av_read_frame().<br>
	 * - muxing: streams are created by the user before avformat_write_header().<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * C type : AVStream**
	 */
	@Field(7) 
	public Pointer<Pointer<AVStream > > streams() {
		return this.io.getPointerField(this, 7);
	}
	/**
	 * A list of all streams in the file. New streams are created with<br>
	 * avformat_new_stream().<br>
	 * * - demuxing: streams are created by libavformat in avformat_open_input().<br>
	 *             If AVFMTCTX_NOHEADER is set in ctx_flags, then new streams may also<br>
	 *             appear in av_read_frame().<br>
	 * - muxing: streams are created by the user before avformat_write_header().<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * C type : AVStream**
	 */
	@Field(7) 
	public AVFormatContext streams(Pointer<Pointer<AVStream > > streams) {
		this.io.setPointerField(this, 7, streams);
		return this;
	}
	/** C type : char[1024] */
	@Array({1024}) 
	@Field(8) 
	public Pointer<Byte > filename() {
		return this.io.getPointerField(this, 8);
	}
	/**
	 * input or output URL. Unlike the old filename field, this field has no<br>
	 * length restriction.<br>
	 * * - demuxing: set by avformat_open_input(), initialized to an empty<br>
	 *             string if url parameter was NULL in avformat_open_input().<br>
	 * - muxing: may be set by the caller before calling avformat_write_header()<br>
	 *           (or avformat_init_output() if that is called first) to a string<br>
	 *           which is freeable by av_free(). Set to an empty string if it<br>
	 *           was NULL in avformat_init_output().<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * C type : char*
	 */
	@Field(9) 
	public Pointer<Byte > url() {
		return this.io.getPointerField(this, 9);
	}
	/**
	 * input or output URL. Unlike the old filename field, this field has no<br>
	 * length restriction.<br>
	 * * - demuxing: set by avformat_open_input(), initialized to an empty<br>
	 *             string if url parameter was NULL in avformat_open_input().<br>
	 * - muxing: may be set by the caller before calling avformat_write_header()<br>
	 *           (or avformat_init_output() if that is called first) to a string<br>
	 *           which is freeable by av_free(). Set to an empty string if it<br>
	 *           was NULL in avformat_init_output().<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * C type : char*
	 */
	@Field(9) 
	public AVFormatContext url(Pointer<Byte > url) {
		this.io.setPointerField(this, 9, url);
		return this;
	}
	/**
	 * Position of the first frame of the component, in<br>
	 * AV_TIME_BASE fractional seconds. NEVER set this value directly:<br>
	 * It is deduced from the AVStream values.<br>
	 * * Demuxing only, set by libavformat.
	 */
	@Field(10) 
	public long start_time() {
		return this.io.getLongField(this, 10);
	}
	/**
	 * Position of the first frame of the component, in<br>
	 * AV_TIME_BASE fractional seconds. NEVER set this value directly:<br>
	 * It is deduced from the AVStream values.<br>
	 * * Demuxing only, set by libavformat.
	 */
	@Field(10) 
	public AVFormatContext start_time(long start_time) {
		this.io.setLongField(this, 10, start_time);
		return this;
	}
	/**
	 * Duration of the stream, in AV_TIME_BASE fractional<br>
	 * seconds. Only set this value if you know none of the individual stream<br>
	 * durations and also do not set any of them. This is deduced from the<br>
	 * AVStream values if not set.<br>
	 * * Demuxing only, set by libavformat.
	 */
	@Field(11) 
	public long duration() {
		return this.io.getLongField(this, 11);
	}
	/**
	 * Duration of the stream, in AV_TIME_BASE fractional<br>
	 * seconds. Only set this value if you know none of the individual stream<br>
	 * durations and also do not set any of them. This is deduced from the<br>
	 * AVStream values if not set.<br>
	 * * Demuxing only, set by libavformat.
	 */
	@Field(11) 
	public AVFormatContext duration(long duration) {
		this.io.setLongField(this, 11, duration);
		return this;
	}
	/**
	 * Total stream bitrate in bit/s, 0 if not<br>
	 * available. Never set it directly if the file_size and the<br>
	 * duration are known as FFmpeg can compute it automatically.
	 */
	@Field(12) 
	public long bit_rate() {
		return this.io.getLongField(this, 12);
	}
	/**
	 * Total stream bitrate in bit/s, 0 if not<br>
	 * available. Never set it directly if the file_size and the<br>
	 * duration are known as FFmpeg can compute it automatically.
	 */
	@Field(12) 
	public AVFormatContext bit_rate(long bit_rate) {
		this.io.setLongField(this, 12, bit_rate);
		return this;
	}
	@Field(13) 
	public int packet_size() {
		return this.io.getIntField(this, 13);
	}
	@Field(13) 
	public AVFormatContext packet_size(int packet_size) {
		this.io.setIntField(this, 13, packet_size);
		return this;
	}
	@Field(14) 
	public int max_delay() {
		return this.io.getIntField(this, 14);
	}
	@Field(14) 
	public AVFormatContext max_delay(int max_delay) {
		this.io.setIntField(this, 14, max_delay);
		return this;
	}
	/**
	 * Flags modifying the (de)muxer behaviour. A combination of AVFMT_FLAG_*.<br>
	 * Set by the user before avformat_open_input() / avformat_write_header().
	 */
	@Field(15) 
	public int flags() {
		return this.io.getIntField(this, 15);
	}
	/**
	 * Flags modifying the (de)muxer behaviour. A combination of AVFMT_FLAG_*.<br>
	 * Set by the user before avformat_open_input() / avformat_write_header().
	 */
	@Field(15) 
	public AVFormatContext flags(int flags) {
		this.io.setIntField(this, 15, flags);
		return this;
	}
	/**
	 * Maximum size of the data read from input for determining<br>
	 * the input container format.<br>
	 * Demuxing only, set by the caller before avformat_open_input().
	 */
	@Field(16) 
	public long probesize() {
		return this.io.getLongField(this, 16);
	}
	/**
	 * Maximum size of the data read from input for determining<br>
	 * the input container format.<br>
	 * Demuxing only, set by the caller before avformat_open_input().
	 */
	@Field(16) 
	public AVFormatContext probesize(long probesize) {
		this.io.setLongField(this, 16, probesize);
		return this;
	}
	/**
	 * Maximum duration (in AV_TIME_BASE units) of the data read<br>
	 * from input in avformat_find_stream_info().<br>
	 * Demuxing only, set by the caller before avformat_find_stream_info().<br>
	 * Can be set to 0 to let avformat choose using a heuristic.
	 */
	@Field(17) 
	public long max_analyze_duration() {
		return this.io.getLongField(this, 17);
	}
	/**
	 * Maximum duration (in AV_TIME_BASE units) of the data read<br>
	 * from input in avformat_find_stream_info().<br>
	 * Demuxing only, set by the caller before avformat_find_stream_info().<br>
	 * Can be set to 0 to let avformat choose using a heuristic.
	 */
	@Field(17) 
	public AVFormatContext max_analyze_duration(long max_analyze_duration) {
		this.io.setLongField(this, 17, max_analyze_duration);
		return this;
	}
	/** C type : const uint8_t* */
	@Field(18) 
	public Pointer<Byte > key() {
		return this.io.getPointerField(this, 18);
	}
	/** C type : const uint8_t* */
	@Field(18) 
	public AVFormatContext key(Pointer<Byte > key) {
		this.io.setPointerField(this, 18, key);
		return this;
	}
	@Field(19) 
	public int keylen() {
		return this.io.getIntField(this, 19);
	}
	@Field(19) 
	public AVFormatContext keylen(int keylen) {
		this.io.setIntField(this, 19, keylen);
		return this;
	}
	@Field(20) 
	public int nb_programs() {
		return this.io.getIntField(this, 20);
	}
	@Field(20) 
	public AVFormatContext nb_programs(int nb_programs) {
		this.io.setIntField(this, 20, nb_programs);
		return this;
	}
	/** C type : AVProgram** */
	@Field(21) 
	public Pointer<Pointer<AVProgram > > programs() {
		return this.io.getPointerField(this, 21);
	}
	/** C type : AVProgram** */
	@Field(21) 
	public AVFormatContext programs(Pointer<Pointer<AVProgram > > programs) {
		this.io.setPointerField(this, 21, programs);
		return this;
	}
	/**
	 * Forced video codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(22) 
	public IntValuedEnum<AVCodecID > video_codec_id() {
		return this.io.getEnumField(this, 22);
	}
	/**
	 * Forced video codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(22) 
	public AVFormatContext video_codec_id(IntValuedEnum<AVCodecID > video_codec_id) {
		this.io.setEnumField(this, 22, video_codec_id);
		return this;
	}
	/**
	 * Forced audio codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(23) 
	public IntValuedEnum<AVCodecID > audio_codec_id() {
		return this.io.getEnumField(this, 23);
	}
	/**
	 * Forced audio codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(23) 
	public AVFormatContext audio_codec_id(IntValuedEnum<AVCodecID > audio_codec_id) {
		this.io.setEnumField(this, 23, audio_codec_id);
		return this;
	}
	/**
	 * Forced subtitle codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(24) 
	public IntValuedEnum<AVCodecID > subtitle_codec_id() {
		return this.io.getEnumField(this, 24);
	}
	/**
	 * Forced subtitle codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(24) 
	public AVFormatContext subtitle_codec_id(IntValuedEnum<AVCodecID > subtitle_codec_id) {
		this.io.setEnumField(this, 24, subtitle_codec_id);
		return this;
	}
	/**
	 * Maximum amount of memory in bytes to use for the index of each stream.<br>
	 * If the index exceeds this size, entries will be discarded as<br>
	 * needed to maintain a smaller size. This can lead to slower or less<br>
	 * accurate seeking (depends on demuxer).<br>
	 * Demuxers for which a full in-memory index is mandatory will ignore<br>
	 * this.<br>
	 * - muxing: unused<br>
	 * - demuxing: set by user
	 */
	@Field(25) 
	public int max_index_size() {
		return this.io.getIntField(this, 25);
	}
	/**
	 * Maximum amount of memory in bytes to use for the index of each stream.<br>
	 * If the index exceeds this size, entries will be discarded as<br>
	 * needed to maintain a smaller size. This can lead to slower or less<br>
	 * accurate seeking (depends on demuxer).<br>
	 * Demuxers for which a full in-memory index is mandatory will ignore<br>
	 * this.<br>
	 * - muxing: unused<br>
	 * - demuxing: set by user
	 */
	@Field(25) 
	public AVFormatContext max_index_size(int max_index_size) {
		this.io.setIntField(this, 25, max_index_size);
		return this;
	}
	/**
	 * Maximum amount of memory in bytes to use for buffering frames<br>
	 * obtained from realtime capture devices.
	 */
	@Field(26) 
	public int max_picture_buffer() {
		return this.io.getIntField(this, 26);
	}
	/**
	 * Maximum amount of memory in bytes to use for buffering frames<br>
	 * obtained from realtime capture devices.
	 */
	@Field(26) 
	public AVFormatContext max_picture_buffer(int max_picture_buffer) {
		this.io.setIntField(this, 26, max_picture_buffer);
		return this;
	}
	/**
	 * Number of chapters in AVChapter array.<br>
	 * When muxing, chapters are normally written in the file header,<br>
	 * so nb_chapters should normally be initialized before write_header<br>
	 * is called. Some muxers (e.g. mov and mkv) can also write chapters<br>
	 * in the trailer.  To write chapters in the trailer, nb_chapters<br>
	 * must be zero when write_header is called and non-zero when<br>
	 * write_trailer is called.<br>
	 * - muxing: set by user<br>
	 * - demuxing: set by libavformat
	 */
	@Field(27) 
	public int nb_chapters() {
		return this.io.getIntField(this, 27);
	}
	/**
	 * Number of chapters in AVChapter array.<br>
	 * When muxing, chapters are normally written in the file header,<br>
	 * so nb_chapters should normally be initialized before write_header<br>
	 * is called. Some muxers (e.g. mov and mkv) can also write chapters<br>
	 * in the trailer.  To write chapters in the trailer, nb_chapters<br>
	 * must be zero when write_header is called and non-zero when<br>
	 * write_trailer is called.<br>
	 * - muxing: set by user<br>
	 * - demuxing: set by libavformat
	 */
	@Field(27) 
	public AVFormatContext nb_chapters(int nb_chapters) {
		this.io.setIntField(this, 27, nb_chapters);
		return this;
	}
	/** C type : AVChapter** */
	@Field(28) 
	public Pointer<Pointer<AVChapter > > chapters() {
		return this.io.getPointerField(this, 28);
	}
	/** C type : AVChapter** */
	@Field(28) 
	public AVFormatContext chapters(Pointer<Pointer<AVChapter > > chapters) {
		this.io.setPointerField(this, 28, chapters);
		return this;
	}
	/**
	 * Metadata that applies to the whole file.<br>
	 * * - demuxing: set by libavformat in avformat_open_input()<br>
	 * - muxing: may be set by the caller before avformat_write_header()<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * C type : AVDictionary*
	 */
	@Field(29) 
	public Pointer<AVDictionary > metadata() {
		return this.io.getPointerField(this, 29);
	}
	/**
	 * Metadata that applies to the whole file.<br>
	 * * - demuxing: set by libavformat in avformat_open_input()<br>
	 * - muxing: may be set by the caller before avformat_write_header()<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * C type : AVDictionary*
	 */
	@Field(29) 
	public AVFormatContext metadata(Pointer<AVDictionary > metadata) {
		this.io.setPointerField(this, 29, metadata);
		return this;
	}
	/**
	 * Start time of the stream in real world time, in microseconds<br>
	 * since the Unix epoch (00:00 1st January 1970). That is, pts=0 in the<br>
	 * stream was captured at this real world time.<br>
	 * - muxing: Set by the caller before avformat_write_header(). If set to<br>
	 *           either 0 or AV_NOPTS_VALUE, then the current wall-time will<br>
	 *           be used.<br>
	 * - demuxing: Set by libavformat. AV_NOPTS_VALUE if unknown. Note that<br>
	 *             the value may become known after some number of frames<br>
	 *             have been received.
	 */
	@Field(30) 
	public long start_time_realtime() {
		return this.io.getLongField(this, 30);
	}
	/**
	 * Start time of the stream in real world time, in microseconds<br>
	 * since the Unix epoch (00:00 1st January 1970). That is, pts=0 in the<br>
	 * stream was captured at this real world time.<br>
	 * - muxing: Set by the caller before avformat_write_header(). If set to<br>
	 *           either 0 or AV_NOPTS_VALUE, then the current wall-time will<br>
	 *           be used.<br>
	 * - demuxing: Set by libavformat. AV_NOPTS_VALUE if unknown. Note that<br>
	 *             the value may become known after some number of frames<br>
	 *             have been received.
	 */
	@Field(30) 
	public AVFormatContext start_time_realtime(long start_time_realtime) {
		this.io.setLongField(this, 30, start_time_realtime);
		return this;
	}
	/**
	 * The number of frames used for determining the framerate in<br>
	 * avformat_find_stream_info().<br>
	 * Demuxing only, set by the caller before avformat_find_stream_info().
	 */
	@Field(31) 
	public int fps_probe_size() {
		return this.io.getIntField(this, 31);
	}
	/**
	 * The number of frames used for determining the framerate in<br>
	 * avformat_find_stream_info().<br>
	 * Demuxing only, set by the caller before avformat_find_stream_info().
	 */
	@Field(31) 
	public AVFormatContext fps_probe_size(int fps_probe_size) {
		this.io.setIntField(this, 31, fps_probe_size);
		return this;
	}
	/**
	 * Error recognition; higher values will detect more errors but may<br>
	 * misdetect some more or less valid parts as errors.<br>
	 * Demuxing only, set by the caller before avformat_open_input().
	 */
	@Field(32) 
	public int error_recognition() {
		return this.io.getIntField(this, 32);
	}
	/**
	 * Error recognition; higher values will detect more errors but may<br>
	 * misdetect some more or less valid parts as errors.<br>
	 * Demuxing only, set by the caller before avformat_open_input().
	 */
	@Field(32) 
	public AVFormatContext error_recognition(int error_recognition) {
		this.io.setIntField(this, 32, error_recognition);
		return this;
	}
	/**
	 * Custom interrupt callbacks for the I/O layer.<br>
	 * * demuxing: set by the user before avformat_open_input().<br>
	 * muxing: set by the user before avformat_write_header()<br>
	 * (mainly useful for AVFMT_NOFILE formats). The callback<br>
	 * should also be passed to avio_open2() if it's used to<br>
	 * open the file.<br>
	 * C type : AVIOInterruptCB
	 */
	@Field(33) 
	public AVIOInterruptCB interrupt_callback() {
		return this.io.getNativeObjectField(this, 33);
	}
	/**
	 * Custom interrupt callbacks for the I/O layer.<br>
	 * * demuxing: set by the user before avformat_open_input().<br>
	 * muxing: set by the user before avformat_write_header()<br>
	 * (mainly useful for AVFMT_NOFILE formats). The callback<br>
	 * should also be passed to avio_open2() if it's used to<br>
	 * open the file.<br>
	 * C type : AVIOInterruptCB
	 */
	@Field(33) 
	public AVFormatContext interrupt_callback(AVIOInterruptCB interrupt_callback) {
		this.io.setNativeObjectField(this, 33, interrupt_callback);
		return this;
	}
	/** Flags to enable debugging. */
	@Field(34) 
	public int debug() {
		return this.io.getIntField(this, 34);
	}
	/** Flags to enable debugging. */
	@Field(34) 
	public AVFormatContext debug(int debug) {
		this.io.setIntField(this, 34, debug);
		return this;
	}
	/**
	 * Maximum buffering duration for interleaving.<br>
	 * * To ensure all the streams are interleaved correctly,<br>
	 * av_interleaved_write_frame() will wait until it has at least one packet<br>
	 * for each stream before actually writing any packets to the output file.<br>
	 * When some streams are "sparse" (i.e. there are large gaps between<br>
	 * successive packets), this can result in excessive buffering.<br>
	 * * This field specifies the maximum difference between the timestamps of the<br>
	 * first and the last packet in the muxing queue, above which libavformat<br>
	 * will output a packet regardless of whether it has queued a packet for all<br>
	 * the streams.<br>
	 * * Muxing only, set by the caller before avformat_write_header().
	 */
	@Field(35) 
	public long max_interleave_delta() {
		return this.io.getLongField(this, 35);
	}
	/**
	 * Maximum buffering duration for interleaving.<br>
	 * * To ensure all the streams are interleaved correctly,<br>
	 * av_interleaved_write_frame() will wait until it has at least one packet<br>
	 * for each stream before actually writing any packets to the output file.<br>
	 * When some streams are "sparse" (i.e. there are large gaps between<br>
	 * successive packets), this can result in excessive buffering.<br>
	 * * This field specifies the maximum difference between the timestamps of the<br>
	 * first and the last packet in the muxing queue, above which libavformat<br>
	 * will output a packet regardless of whether it has queued a packet for all<br>
	 * the streams.<br>
	 * * Muxing only, set by the caller before avformat_write_header().
	 */
	@Field(35) 
	public AVFormatContext max_interleave_delta(long max_interleave_delta) {
		this.io.setLongField(this, 35, max_interleave_delta);
		return this;
	}
	/**
	 * Allow non-standard and experimental extension<br>
	 * @see AVCodecContext.strict_std_compliance
	 */
	@Field(36) 
	public int strict_std_compliance() {
		return this.io.getIntField(this, 36);
	}
	/**
	 * Allow non-standard and experimental extension<br>
	 * @see AVCodecContext.strict_std_compliance
	 */
	@Field(36) 
	public AVFormatContext strict_std_compliance(int strict_std_compliance) {
		this.io.setIntField(this, 36, strict_std_compliance);
		return this;
	}
	/**
	 * Flags indicating events happening on the file, a combination of<br>
	 * AVFMT_EVENT_FLAG_*.<br>
	 * * - demuxing: may be set by the demuxer in avformat_open_input(),<br>
	 *   avformat_find_stream_info() and av_read_frame(). Flags must be cleared<br>
	 *   by the user once the event has been handled.<br>
	 * - muxing: may be set by the user after avformat_write_header() to<br>
	 *   indicate a user-triggered event.  The muxer will clear the flags for<br>
	 *   events it has handled in av_[interleaved]_write_frame().
	 */
	@Field(37) 
	public int event_flags() {
		return this.io.getIntField(this, 37);
	}
	/**
	 * Flags indicating events happening on the file, a combination of<br>
	 * AVFMT_EVENT_FLAG_*.<br>
	 * * - demuxing: may be set by the demuxer in avformat_open_input(),<br>
	 *   avformat_find_stream_info() and av_read_frame(). Flags must be cleared<br>
	 *   by the user once the event has been handled.<br>
	 * - muxing: may be set by the user after avformat_write_header() to<br>
	 *   indicate a user-triggered event.  The muxer will clear the flags for<br>
	 *   events it has handled in av_[interleaved]_write_frame().
	 */
	@Field(37) 
	public AVFormatContext event_flags(int event_flags) {
		this.io.setIntField(this, 37, event_flags);
		return this;
	}
	/**
	 * Maximum number of packets to read while waiting for the first timestamp.<br>
	 * Decoding only.
	 */
	@Field(38) 
	public int max_ts_probe() {
		return this.io.getIntField(this, 38);
	}
	/**
	 * Maximum number of packets to read while waiting for the first timestamp.<br>
	 * Decoding only.
	 */
	@Field(38) 
	public AVFormatContext max_ts_probe(int max_ts_probe) {
		this.io.setIntField(this, 38, max_ts_probe);
		return this;
	}
	/**
	 * Avoid negative timestamps during muxing.<br>
	 * Any value of the AVFMT_AVOID_NEG_TS_* constants.<br>
	 * Note, this only works when using av_interleaved_write_frame. (interleave_packet_per_dts is in use)<br>
	 * - muxing: Set by user<br>
	 * - demuxing: unused
	 */
	@Field(39) 
	public int avoid_negative_ts() {
		return this.io.getIntField(this, 39);
	}
	/**
	 * Avoid negative timestamps during muxing.<br>
	 * Any value of the AVFMT_AVOID_NEG_TS_* constants.<br>
	 * Note, this only works when using av_interleaved_write_frame. (interleave_packet_per_dts is in use)<br>
	 * - muxing: Set by user<br>
	 * - demuxing: unused
	 */
	@Field(39) 
	public AVFormatContext avoid_negative_ts(int avoid_negative_ts) {
		this.io.setIntField(this, 39, avoid_negative_ts);
		return this;
	}
	/**
	 * Transport stream id.<br>
	 * This will be moved into demuxer private options. Thus no API/ABI compatibility
	 */
	@Field(40) 
	public int ts_id() {
		return this.io.getIntField(this, 40);
	}
	/**
	 * Transport stream id.<br>
	 * This will be moved into demuxer private options. Thus no API/ABI compatibility
	 */
	@Field(40) 
	public AVFormatContext ts_id(int ts_id) {
		this.io.setIntField(this, 40, ts_id);
		return this;
	}
	/**
	 * Audio preload in microseconds.<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user<br>
	 * - decoding: unused
	 */
	@Field(41) 
	public int audio_preload() {
		return this.io.getIntField(this, 41);
	}
	/**
	 * Audio preload in microseconds.<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user<br>
	 * - decoding: unused
	 */
	@Field(41) 
	public AVFormatContext audio_preload(int audio_preload) {
		this.io.setIntField(this, 41, audio_preload);
		return this;
	}
	/**
	 * Max chunk time in microseconds.<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user<br>
	 * - decoding: unused
	 */
	@Field(42) 
	public int max_chunk_duration() {
		return this.io.getIntField(this, 42);
	}
	/**
	 * Max chunk time in microseconds.<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user<br>
	 * - decoding: unused
	 */
	@Field(42) 
	public AVFormatContext max_chunk_duration(int max_chunk_duration) {
		this.io.setIntField(this, 42, max_chunk_duration);
		return this;
	}
	/**
	 * Max chunk size in bytes<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user<br>
	 * - decoding: unused
	 */
	@Field(43) 
	public int max_chunk_size() {
		return this.io.getIntField(this, 43);
	}
	/**
	 * Max chunk size in bytes<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user<br>
	 * - decoding: unused
	 */
	@Field(43) 
	public AVFormatContext max_chunk_size(int max_chunk_size) {
		this.io.setIntField(this, 43, max_chunk_size);
		return this;
	}
	/**
	 * forces the use of wallclock timestamps as pts/dts of packets<br>
	 * This has undefined results in the presence of B frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user
	 */
	@Field(44) 
	public int use_wallclock_as_timestamps() {
		return this.io.getIntField(this, 44);
	}
	/**
	 * forces the use of wallclock timestamps as pts/dts of packets<br>
	 * This has undefined results in the presence of B frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user
	 */
	@Field(44) 
	public AVFormatContext use_wallclock_as_timestamps(int use_wallclock_as_timestamps) {
		this.io.setIntField(this, 44, use_wallclock_as_timestamps);
		return this;
	}
	/**
	 * avio flags, used to force AVIO_FLAG_DIRECT.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user
	 */
	@Field(45) 
	public int avio_flags() {
		return this.io.getIntField(this, 45);
	}
	/**
	 * avio flags, used to force AVIO_FLAG_DIRECT.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user
	 */
	@Field(45) 
	public AVFormatContext avio_flags(int avio_flags) {
		this.io.setIntField(this, 45, avio_flags);
		return this;
	}
	/**
	 * The duration field can be estimated through various ways, and this field can be used<br>
	 * to know how the duration was estimated.<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user<br>
	 * C type : AVDurationEstimationMethod
	 */
	@Field(46) 
	public IntValuedEnum<AVDurationEstimationMethod > duration_estimation_method() {
		return this.io.getEnumField(this, 46);
	}
	/**
	 * The duration field can be estimated through various ways, and this field can be used<br>
	 * to know how the duration was estimated.<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user<br>
	 * C type : AVDurationEstimationMethod
	 */
	@Field(46) 
	public AVFormatContext duration_estimation_method(IntValuedEnum<AVDurationEstimationMethod > duration_estimation_method) {
		this.io.setEnumField(this, 46, duration_estimation_method);
		return this;
	}
	/**
	 * Skip initial bytes when opening stream<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user
	 */
	@Field(47) 
	public long skip_initial_bytes() {
		return this.io.getLongField(this, 47);
	}
	/**
	 * Skip initial bytes when opening stream<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user
	 */
	@Field(47) 
	public AVFormatContext skip_initial_bytes(long skip_initial_bytes) {
		this.io.setLongField(this, 47, skip_initial_bytes);
		return this;
	}
	/**
	 * Correct single timestamp overflows<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user
	 */
	@Field(48) 
	public int correct_ts_overflow() {
		return this.io.getIntField(this, 48);
	}
	/**
	 * Correct single timestamp overflows<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user
	 */
	@Field(48) 
	public AVFormatContext correct_ts_overflow(int correct_ts_overflow) {
		this.io.setIntField(this, 48, correct_ts_overflow);
		return this;
	}
	/**
	 * Force seeking to any (also non key) frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user
	 */
	@Field(49) 
	public int seek2any() {
		return this.io.getIntField(this, 49);
	}
	/**
	 * Force seeking to any (also non key) frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user
	 */
	@Field(49) 
	public AVFormatContext seek2any(int seek2any) {
		this.io.setIntField(this, 49, seek2any);
		return this;
	}
	/**
	 * Flush the I/O context after each packet.<br>
	 * - encoding: Set by user<br>
	 * - decoding: unused
	 */
	@Field(50) 
	public int flush_packets() {
		return this.io.getIntField(this, 50);
	}
	/**
	 * Flush the I/O context after each packet.<br>
	 * - encoding: Set by user<br>
	 * - decoding: unused
	 */
	@Field(50) 
	public AVFormatContext flush_packets(int flush_packets) {
		this.io.setIntField(this, 50, flush_packets);
		return this;
	}
	/**
	 * format probing score.<br>
	 * The maximal score is AVPROBE_SCORE_MAX, its set when the demuxer probes<br>
	 * the format.<br>
	 * - encoding: unused<br>
	 * - decoding: set by avformat, read by user
	 */
	@Field(51) 
	public int probe_score() {
		return this.io.getIntField(this, 51);
	}
	/**
	 * format probing score.<br>
	 * The maximal score is AVPROBE_SCORE_MAX, its set when the demuxer probes<br>
	 * the format.<br>
	 * - encoding: unused<br>
	 * - decoding: set by avformat, read by user
	 */
	@Field(51) 
	public AVFormatContext probe_score(int probe_score) {
		this.io.setIntField(this, 51, probe_score);
		return this;
	}
	/**
	 * number of bytes to read maximally to identify format.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user
	 */
	@Field(52) 
	public int format_probesize() {
		return this.io.getIntField(this, 52);
	}
	/**
	 * number of bytes to read maximally to identify format.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user
	 */
	@Field(52) 
	public AVFormatContext format_probesize(int format_probesize) {
		this.io.setIntField(this, 52, format_probesize);
		return this;
	}
	/**
	 * ',' separated list of allowed decoders.<br>
	 * If NULL then all are allowed<br>
	 * - encoding: unused<br>
	 * - decoding: set by user<br>
	 * C type : char*
	 */
	@Field(53) 
	public Pointer<Byte > codec_whitelist() {
		return this.io.getPointerField(this, 53);
	}
	/**
	 * ',' separated list of allowed decoders.<br>
	 * If NULL then all are allowed<br>
	 * - encoding: unused<br>
	 * - decoding: set by user<br>
	 * C type : char*
	 */
	@Field(53) 
	public AVFormatContext codec_whitelist(Pointer<Byte > codec_whitelist) {
		this.io.setPointerField(this, 53, codec_whitelist);
		return this;
	}
	/**
	 * ',' separated list of allowed demuxers.<br>
	 * If NULL then all are allowed<br>
	 * - encoding: unused<br>
	 * - decoding: set by user<br>
	 * C type : char*
	 */
	@Field(54) 
	public Pointer<Byte > format_whitelist() {
		return this.io.getPointerField(this, 54);
	}
	/**
	 * ',' separated list of allowed demuxers.<br>
	 * If NULL then all are allowed<br>
	 * - encoding: unused<br>
	 * - decoding: set by user<br>
	 * C type : char*
	 */
	@Field(54) 
	public AVFormatContext format_whitelist(Pointer<Byte > format_whitelist) {
		this.io.setPointerField(this, 54, format_whitelist);
		return this;
	}
	/**
	 * An opaque field for libavformat internal usage.<br>
	 * Must not be accessed in any way by callers.<br>
	 * C type : AVFormatInternal*
	 */
	@Field(55) 
	public Pointer<AVFormatInternal > internal() {
		return this.io.getPointerField(this, 55);
	}
	/**
	 * An opaque field for libavformat internal usage.<br>
	 * Must not be accessed in any way by callers.<br>
	 * C type : AVFormatInternal*
	 */
	@Field(55) 
	public AVFormatContext internal(Pointer<AVFormatInternal > internal) {
		this.io.setPointerField(this, 55, internal);
		return this;
	}
	/**
	 * IO repositioned flag.<br>
	 * This is set by avformat when the underlaying IO context read pointer<br>
	 * is repositioned, for example when doing byte based seeking.<br>
	 * Demuxers can use the flag to detect such changes.
	 */
	@Field(56) 
	public int io_repositioned() {
		return this.io.getIntField(this, 56);
	}
	/**
	 * IO repositioned flag.<br>
	 * This is set by avformat when the underlaying IO context read pointer<br>
	 * is repositioned, for example when doing byte based seeking.<br>
	 * Demuxers can use the flag to detect such changes.
	 */
	@Field(56) 
	public AVFormatContext io_repositioned(int io_repositioned) {
		this.io.setIntField(this, 56, io_repositioned);
		return this;
	}
	/**
	 * Forced video codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user<br>
	 * C type : AVCodec*
	 */
	@Field(57) 
	public Pointer<AVCodec > video_codec() {
		return this.io.getPointerField(this, 57);
	}
	/**
	 * Forced video codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user<br>
	 * C type : AVCodec*
	 */
	@Field(57) 
	public AVFormatContext video_codec(Pointer<AVCodec > video_codec) {
		this.io.setPointerField(this, 57, video_codec);
		return this;
	}
	/**
	 * Forced audio codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user<br>
	 * C type : AVCodec*
	 */
	@Field(58) 
	public Pointer<AVCodec > audio_codec() {
		return this.io.getPointerField(this, 58);
	}
	/**
	 * Forced audio codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user<br>
	 * C type : AVCodec*
	 */
	@Field(58) 
	public AVFormatContext audio_codec(Pointer<AVCodec > audio_codec) {
		this.io.setPointerField(this, 58, audio_codec);
		return this;
	}
	/**
	 * Forced subtitle codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user<br>
	 * C type : AVCodec*
	 */
	@Field(59) 
	public Pointer<AVCodec > subtitle_codec() {
		return this.io.getPointerField(this, 59);
	}
	/**
	 * Forced subtitle codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user<br>
	 * C type : AVCodec*
	 */
	@Field(59) 
	public AVFormatContext subtitle_codec(Pointer<AVCodec > subtitle_codec) {
		this.io.setPointerField(this, 59, subtitle_codec);
		return this;
	}
	/**
	 * Forced data codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user<br>
	 * C type : AVCodec*
	 */
	@Field(60) 
	public Pointer<AVCodec > data_codec() {
		return this.io.getPointerField(this, 60);
	}
	/**
	 * Forced data codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user<br>
	 * C type : AVCodec*
	 */
	@Field(60) 
	public AVFormatContext data_codec(Pointer<AVCodec > data_codec) {
		this.io.setPointerField(this, 60, data_codec);
		return this;
	}
	/**
	 * Number of bytes to be written as padding in a metadata header.<br>
	 * Demuxing: Unused.<br>
	 * Muxing: Set by user via av_format_set_metadata_header_padding.
	 */
	@Field(61) 
	public int metadata_header_padding() {
		return this.io.getIntField(this, 61);
	}
	/**
	 * Number of bytes to be written as padding in a metadata header.<br>
	 * Demuxing: Unused.<br>
	 * Muxing: Set by user via av_format_set_metadata_header_padding.
	 */
	@Field(61) 
	public AVFormatContext metadata_header_padding(int metadata_header_padding) {
		this.io.setIntField(this, 61, metadata_header_padding);
		return this;
	}
	/**
	 * User data.<br>
	 * This is a place for some private data of the user.<br>
	 * C type : void*
	 */
	@Field(62) 
	public Pointer<? > opaque() {
		return this.io.getPointerField(this, 62);
	}
	/**
	 * User data.<br>
	 * This is a place for some private data of the user.<br>
	 * C type : void*
	 */
	@Field(62) 
	public AVFormatContext opaque(Pointer<? > opaque) {
		this.io.setPointerField(this, 62, opaque);
		return this;
	}
	/**
	 * Callback used by devices to communicate with application.<br>
	 * C type : av_format_control_message
	 */
	@Field(63) 
	public Pointer<av_format_control_message > control_message_cb() {
		return this.io.getPointerField(this, 63);
	}
	/**
	 * Callback used by devices to communicate with application.<br>
	 * C type : av_format_control_message
	 */
	@Field(63) 
	public AVFormatContext control_message_cb(Pointer<av_format_control_message > control_message_cb) {
		this.io.setPointerField(this, 63, control_message_cb);
		return this;
	}
	/**
	 * Output timestamp offset, in microseconds.<br>
	 * Muxing: set by user
	 */
	@Field(64) 
	public long output_ts_offset() {
		return this.io.getLongField(this, 64);
	}
	/**
	 * Output timestamp offset, in microseconds.<br>
	 * Muxing: set by user
	 */
	@Field(64) 
	public AVFormatContext output_ts_offset(long output_ts_offset) {
		this.io.setLongField(this, 64, output_ts_offset);
		return this;
	}
	/**
	 * dump format separator.<br>
	 * can be ", " or "\n      " or anything else<br>
	 * - muxing: Set by user.<br>
	 * - demuxing: Set by user.<br>
	 * C type : uint8_t*
	 */
	@Field(65) 
	public Pointer<Byte > dump_separator() {
		return this.io.getPointerField(this, 65);
	}
	/**
	 * dump format separator.<br>
	 * can be ", " or "\n      " or anything else<br>
	 * - muxing: Set by user.<br>
	 * - demuxing: Set by user.<br>
	 * C type : uint8_t*
	 */
	@Field(65) 
	public AVFormatContext dump_separator(Pointer<Byte > dump_separator) {
		this.io.setPointerField(this, 65, dump_separator);
		return this;
	}
	/**
	 * Forced Data codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(66) 
	public IntValuedEnum<AVCodecID > data_codec_id() {
		return this.io.getEnumField(this, 66);
	}
	/**
	 * Forced Data codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(66) 
	public AVFormatContext data_codec_id(IntValuedEnum<AVCodecID > data_codec_id) {
		this.io.setEnumField(this, 66, data_codec_id);
		return this;
	}
	/** C type : open_cb_callback* */
	@Field(67) 
	public Pointer<AVFormatContext.open_cb_callback > open_cb() {
		return this.io.getPointerField(this, 67);
	}
	/** C type : open_cb_callback* */
	@Field(67) 
	public AVFormatContext open_cb(Pointer<AVFormatContext.open_cb_callback > open_cb) {
		this.io.setPointerField(this, 67, open_cb);
		return this;
	}
	/**
	 * ',' separated list of allowed protocols.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user<br>
	 * C type : char*
	 */
	@Field(68) 
	public Pointer<Byte > protocol_whitelist() {
		return this.io.getPointerField(this, 68);
	}
	/**
	 * ',' separated list of allowed protocols.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user<br>
	 * C type : char*
	 */
	@Field(68) 
	public AVFormatContext protocol_whitelist(Pointer<Byte > protocol_whitelist) {
		this.io.setPointerField(this, 68, protocol_whitelist);
		return this;
	}
	/**
	 * A callback for opening new IO streams.<br>
	 * * Whenever a muxer or a demuxer needs to open an IO stream (typically from<br>
	 * avformat_open_input() for demuxers, but for certain formats can happen at<br>
	 * other times as well), it will call this callback to obtain an IO context.<br>
	 * * @param s the format context<br>
	 * @param pb on success, the newly opened IO context should be returned here<br>
	 * @param url the url to open<br>
	 * @param flags a combination of AVIO_FLAG_*<br>
	 * @param options a dictionary of additional options, with the same<br>
	 *                semantics as in avio_open2()<br>
	 * @return 0 on success, a negative AVERROR code on failure<br>
	 * * @note Certain muxers and demuxers do nesting, i.e. they open one or more<br>
	 * additional internal format contexts. Thus the AVFormatContext pointer<br>
	 * passed to this callback may be different from the one facing the caller.<br>
	 * It will, however, have the same 'opaque' field.<br>
	 * C type : io_open_callback*
	 */
	@Field(69) 
	public Pointer<AVFormatContext.io_open_callback > io_open() {
		return this.io.getPointerField(this, 69);
	}
	/**
	 * A callback for opening new IO streams.<br>
	 * * Whenever a muxer or a demuxer needs to open an IO stream (typically from<br>
	 * avformat_open_input() for demuxers, but for certain formats can happen at<br>
	 * other times as well), it will call this callback to obtain an IO context.<br>
	 * * @param s the format context<br>
	 * @param pb on success, the newly opened IO context should be returned here<br>
	 * @param url the url to open<br>
	 * @param flags a combination of AVIO_FLAG_*<br>
	 * @param options a dictionary of additional options, with the same<br>
	 *                semantics as in avio_open2()<br>
	 * @return 0 on success, a negative AVERROR code on failure<br>
	 * * @note Certain muxers and demuxers do nesting, i.e. they open one or more<br>
	 * additional internal format contexts. Thus the AVFormatContext pointer<br>
	 * passed to this callback may be different from the one facing the caller.<br>
	 * It will, however, have the same 'opaque' field.<br>
	 * C type : io_open_callback*
	 */
	@Field(69) 
	public AVFormatContext io_open(Pointer<AVFormatContext.io_open_callback > io_open) {
		this.io.setPointerField(this, 69, io_open);
		return this;
	}
	/**
	 * A callback for closing the streams opened with AVFormatContext.io_open().<br>
	 * C type : io_close_callback*
	 */
	@Field(70) 
	public Pointer<AVFormatContext.io_close_callback > io_close() {
		return this.io.getPointerField(this, 70);
	}
	/**
	 * A callback for closing the streams opened with AVFormatContext.io_open().<br>
	 * C type : io_close_callback*
	 */
	@Field(70) 
	public AVFormatContext io_close(Pointer<AVFormatContext.io_close_callback > io_close) {
		this.io.setPointerField(this, 70, io_close);
		return this;
	}
	/**
	 * ',' separated list of disallowed protocols.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user<br>
	 * C type : char*
	 */
	@Field(71) 
	public Pointer<Byte > protocol_blacklist() {
		return this.io.getPointerField(this, 71);
	}
	/**
	 * ',' separated list of disallowed protocols.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user<br>
	 * C type : char*
	 */
	@Field(71) 
	public AVFormatContext protocol_blacklist(Pointer<Byte > protocol_blacklist) {
		this.io.setPointerField(this, 71, protocol_blacklist);
		return this;
	}
	/**
	 * The maximum number of streams.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user
	 */
	@Field(72) 
	public int max_streams() {
		return this.io.getIntField(this, 72);
	}
	/**
	 * The maximum number of streams.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user
	 */
	@Field(72) 
	public AVFormatContext max_streams(int max_streams) {
		this.io.setIntField(this, 72, max_streams);
		return this;
	}
	/**
	 * Skip duration calcuation in estimate_timings_from_pts.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user
	 */
	@Field(73) 
	public int skip_estimate_duration_from_pts() {
		return this.io.getIntField(this, 73);
	}
	/**
	 * Skip duration calcuation in estimate_timings_from_pts.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user
	 */
	@Field(73) 
	public AVFormatContext skip_estimate_duration_from_pts(int skip_estimate_duration_from_pts) {
		this.io.setIntField(this, 73, skip_estimate_duration_from_pts);
		return this;
	}
	/**
	 * Maximum number of packets that can be probed<br>
	 * - encoding: unused<br>
	 * - decoding: set by user
	 */
	@Field(74) 
	public int max_probe_packets() {
		return this.io.getIntField(this, 74);
	}
	/**
	 * Maximum number of packets that can be probed<br>
	 * - encoding: unused<br>
	 * - decoding: set by user
	 */
	@Field(74) 
	public AVFormatContext max_probe_packets(int max_probe_packets) {
		this.io.setIntField(this, 74, max_probe_packets);
		return this;
	}
	/** <i>native declaration : libavformat/avformat.h:1052</i> */
	public static abstract class open_cb_callback extends Callback<open_cb_callback > {
		public int apply(Pointer<AVFormatContext > s, Pointer<Pointer > p, Pointer<Byte > url, int flags, Pointer<AVIOInterruptCB > int_cb, Pointer<Pointer > options) {
			return apply(Pointer.getPeer(s), Pointer.getPeer(p), Pointer.getPeer(url), flags, Pointer.getPeer(int_cb), Pointer.getPeer(options));
		}
		public int apply(@Ptr long s, @Ptr long p, @Ptr long url, int flags, @Ptr long int_cb, @Ptr long options) {
			return apply(Pointer.pointerToAddress(s, AVFormatContext.class), Pointer.pointerToAddress(p, Pointer.class), Pointer.pointerToAddress(url, Byte.class), flags, Pointer.pointerToAddress(int_cb, AVIOInterruptCB.class), Pointer.pointerToAddress(options, Pointer.class));
		}
	};
	/** <i>native declaration : libavformat/avformat.h:1053</i> */
	public static abstract class io_open_callback extends Callback<io_open_callback > {
		public int apply(Pointer<AVFormatContext > s, Pointer<Pointer > pb, Pointer<Byte > url, int flags, Pointer<Pointer > options) {
			return apply(Pointer.getPeer(s), Pointer.getPeer(pb), Pointer.getPeer(url), flags, Pointer.getPeer(options));
		}
		public int apply(@Ptr long s, @Ptr long pb, @Ptr long url, int flags, @Ptr long options) {
			return apply(Pointer.pointerToAddress(s, AVFormatContext.class), Pointer.pointerToAddress(pb, Pointer.class), Pointer.pointerToAddress(url, Byte.class), flags, Pointer.pointerToAddress(options, Pointer.class));
		}
	};
	/** <i>native declaration : libavformat/avformat.h:1054</i> */
	public static abstract class io_close_callback extends Callback<io_close_callback > {
		public void apply(Pointer<AVFormatContext > s, Pointer<AVIOContext > pb) {
			apply(Pointer.getPeer(s), Pointer.getPeer(pb));
		}
		public void apply(@Ptr long s, @Ptr long pb) {
			apply(Pointer.pointerToAddress(s, AVFormatContext.class), Pointer.pointerToAddress(pb, AVIOContext.class));
		}
	};
	@Struct(customizer=AlignmentCustomizer.class)
	public AVFormatContext() {
		super();
	}
	@Struct(customizer=AlignmentCustomizer.class)
	public AVFormatContext(Pointer pointer) {
		super(pointer);
	}
}
