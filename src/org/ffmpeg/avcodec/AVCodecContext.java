package org.ffmpeg.avcodec;
import org.bridj.BridJ;
import org.bridj.Callback;
import org.bridj.IntValuedEnum;
import org.bridj.Pointer;
import org.bridj.StructObject;
import org.bridj.ann.Array;
import org.bridj.ann.CLong;
import org.bridj.ann.Field;
import org.bridj.ann.Library;
import org.bridj.ann.Ptr;
import org.bridj.ann.Struct;
import org.ffmpeg.avcodec.AvcodecLibrary.AVAudioServiceType;
import org.ffmpeg.avcodec.AvcodecLibrary.AVCodecID;
import org.ffmpeg.avcodec.AvcodecLibrary.AVDiscard;
import org.ffmpeg.avcodec.AvcodecLibrary.AVFieldOrder;
import org.ffmpeg.avutil.AVBufferRef;
import org.ffmpeg.avutil.AVClass;
import org.ffmpeg.avutil.AVFrame;
import org.ffmpeg.avutil.AVRational;
import org.ffmpeg.avutil.AvutilLibrary.AVChromaLocation;
import org.ffmpeg.avutil.AvutilLibrary.AVColorPrimaries;
import org.ffmpeg.avutil.AvutilLibrary.AVColorRange;
import org.ffmpeg.avutil.AvutilLibrary.AVColorSpace;
import org.ffmpeg.avutil.AvutilLibrary.AVColorTransferCharacteristic;
import org.ffmpeg.avutil.AvutilLibrary.AVMediaType;
import org.ffmpeg.avutil.AvutilLibrary.AVPixelFormat;
import org.ffmpeg.avutil.AvutilLibrary.AVSampleFormat;
import org.ffmpeg.util.AlignmentCustomizer;
/**
 * <i>native declaration : ./libavcodec/avcodec.h:2203</i><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> or <a href="http://bridj.googlecode.com/">BridJ</a> .
 */
@Library("avcodec") 
public class AVCodecContext extends StructObject {
	static {
		BridJ.register();
	}
	/**
	 * information on struct for av_log<br>
	 * - set by avcodec_alloc_context3<br>
	 * C type : const AVClass*
	 */
	@Field(0) 
	public Pointer<AVClass > av_class() {
		return this.io.getPointerField(this, 0);
	}
	/**
	 * information on struct for av_log<br>
	 * - set by avcodec_alloc_context3<br>
	 * C type : const AVClass*
	 */
	@Field(0) 
	public AVCodecContext av_class(Pointer<AVClass > av_class) {
		this.io.setPointerField(this, 0, av_class);
		return this;
	}
	@Field(1) 
	public int log_level_offset() {
		return this.io.getIntField(this, 1);
	}
	@Field(1) 
	public AVCodecContext log_level_offset(int log_level_offset) {
		this.io.setIntField(this, 1, log_level_offset);
		return this;
	}
	/**
	 * see AVMEDIA_TYPE_xxx<br>
	 * C type : AVMediaType
	 */
	@Field(2) 
	public IntValuedEnum<AVMediaType > codec_type() {
		return this.io.getEnumField(this, 2);
	}
	/**
	 * see AVMEDIA_TYPE_xxx<br>
	 * C type : AVMediaType
	 */
	@Field(2) 
	public AVCodecContext codec_type(IntValuedEnum<AVMediaType > codec_type) {
		this.io.setEnumField(this, 2, codec_type);
		return this;
	}
	/** C type : AVCodec* */
	@Field(3) 
	public Pointer<AVCodec > codec() {
		return this.io.getPointerField(this, 3);
	}
	/** C type : AVCodec* */
	@Field(3) 
	public AVCodecContext codec(Pointer<AVCodec > codec) {
		this.io.setPointerField(this, 3, codec);
		return this;
	}
	/**
	 * see AV_CODEC_ID_xxx<br>
	 * C type : AVCodecID
	 */
	@Field(4) 
	public IntValuedEnum<AVCodecID > codec_id() {
		return this.io.getEnumField(this, 4);
	}
	/**
	 * see AV_CODEC_ID_xxx<br>
	 * C type : AVCodecID
	 */
	@Field(4) 
	public AVCodecContext codec_id(IntValuedEnum<AVCodecID > codec_id) {
		this.io.setEnumField(this, 4, codec_id);
		return this;
	}
	/**
	 * fourcc (LSB first, so "ABCD" -> ('D'<<24) + ('C'<<16) + ('B'<<8) + 'A').<br>
	 * This is used to work around some encoder bugs.<br>
	 * A demuxer should set this to what is stored in the field used to identify the codec.<br>
	 * If there are multiple such fields in a container then the demuxer should choose the one<br>
	 * which maximizes the information about the used codec.<br>
	 * If the codec tag field in a container is larger than 32 bits then the demuxer should<br>
	 * remap the longer ID to 32 bits with a table or other structure. Alternatively a new<br>
	 * extra_codec_tag + size could be added but for this a clear advantage must be demonstrated<br>
	 * first.<br>
	 * - encoding: Set by user, if not then the default based on codec_id will be used.<br>
	 * - decoding: Set by user, will be converted to uppercase by libavcodec during init.
	 */
	@Field(5) 
	public int codec_tag() {
		return this.io.getIntField(this, 5);
	}
	/**
	 * fourcc (LSB first, so "ABCD" -> ('D'<<24) + ('C'<<16) + ('B'<<8) + 'A').<br>
	 * This is used to work around some encoder bugs.<br>
	 * A demuxer should set this to what is stored in the field used to identify the codec.<br>
	 * If there are multiple such fields in a container then the demuxer should choose the one<br>
	 * which maximizes the information about the used codec.<br>
	 * If the codec tag field in a container is larger than 32 bits then the demuxer should<br>
	 * remap the longer ID to 32 bits with a table or other structure. Alternatively a new<br>
	 * extra_codec_tag + size could be added but for this a clear advantage must be demonstrated<br>
	 * first.<br>
	 * - encoding: Set by user, if not then the default based on codec_id will be used.<br>
	 * - decoding: Set by user, will be converted to uppercase by libavcodec during init.
	 */
	@Field(5) 
	public AVCodecContext codec_tag(int codec_tag) {
		this.io.setIntField(this, 5, codec_tag);
		return this;
	}
	/** C type : void* */
	@Field(6) 
	public Pointer<? > priv_data() {
		return this.io.getPointerField(this, 6);
	}
	/** C type : void* */
	@Field(6) 
	public AVCodecContext priv_data(Pointer<? > priv_data) {
		this.io.setPointerField(this, 6, priv_data);
		return this;
	}
	/**
	 * Private context used for internal data.<br>
	 * * Unlike priv_data, this is not codec-specific. It is used in general<br>
	 * libavcodec functions.<br>
	 * C type : AVCodecInternal*
	 */
	@Field(7) 
	public Pointer<AVCodecInternal > internal() {
		return this.io.getPointerField(this, 7);
	}
	/**
	 * Private context used for internal data.<br>
	 * * Unlike priv_data, this is not codec-specific. It is used in general<br>
	 * libavcodec functions.<br>
	 * C type : AVCodecInternal*
	 */
	@Field(7) 
	public AVCodecContext internal(Pointer<AVCodecInternal > internal) {
		this.io.setPointerField(this, 7, internal);
		return this;
	}
	/**
	 * Private data of the user, can be used to carry app specific stuff.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.<br>
	 * C type : void*
	 */
	@Field(8) 
	public Pointer<? > opaque() {
		return this.io.getPointerField(this, 8);
	}
	/**
	 * Private data of the user, can be used to carry app specific stuff.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.<br>
	 * C type : void*
	 */
	@Field(8) 
	public AVCodecContext opaque(Pointer<? > opaque) {
		this.io.setPointerField(this, 8, opaque);
		return this;
	}
	/**
	 * the average bitrate<br>
	 * - encoding: Set by user; unused for constant quantizer encoding.<br>
	 * - decoding: Set by user, may be overwritten by libavcodec<br>
	 *             if this info is available in the stream
	 */
	@Field(9) 
	public long bit_rate() {
		return this.io.getLongField(this, 9);
	}
	/**
	 * the average bitrate<br>
	 * - encoding: Set by user; unused for constant quantizer encoding.<br>
	 * - decoding: Set by user, may be overwritten by libavcodec<br>
	 *             if this info is available in the stream
	 */
	@Field(9) 
	public AVCodecContext bit_rate(long bit_rate) {
		this.io.setLongField(this, 9, bit_rate);
		return this;
	}
	/**
	 * number of bits the bitstream is allowed to diverge from the reference.<br>
	 *           the reference can be CBR (for CBR pass1) or VBR (for pass2)<br>
	 * - encoding: Set by user; unused for constant quantizer encoding.<br>
	 * - decoding: unused
	 */
	@Field(10) 
	public int bit_rate_tolerance() {
		return this.io.getIntField(this, 10);
	}
	/**
	 * number of bits the bitstream is allowed to diverge from the reference.<br>
	 *           the reference can be CBR (for CBR pass1) or VBR (for pass2)<br>
	 * - encoding: Set by user; unused for constant quantizer encoding.<br>
	 * - decoding: unused
	 */
	@Field(10) 
	public AVCodecContext bit_rate_tolerance(int bit_rate_tolerance) {
		this.io.setIntField(this, 10, bit_rate_tolerance);
		return this;
	}
	/**
	 * Global quality for codecs which cannot change it per frame.<br>
	 * This should be proportional to MPEG-1/2/4 qscale.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(11) 
	public int global_quality() {
		return this.io.getIntField(this, 11);
	}
	/**
	 * Global quality for codecs which cannot change it per frame.<br>
	 * This should be proportional to MPEG-1/2/4 qscale.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(11) 
	public AVCodecContext global_quality(int global_quality) {
		this.io.setIntField(this, 11, global_quality);
		return this;
	}
	/**
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(12) 
	public int compression_level() {
		return this.io.getIntField(this, 12);
	}
	/**
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(12) 
	public AVCodecContext compression_level(int compression_level) {
		this.io.setIntField(this, 12, compression_level);
		return this;
	}
	/**
	 * AV_CODEC_FLAG_*.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(13) 
	public int flags() {
		return this.io.getIntField(this, 13);
	}
	/**
	 * AV_CODEC_FLAG_*.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(13) 
	public AVCodecContext flags(int flags) {
		this.io.setIntField(this, 13, flags);
		return this;
	}
	/**
	 * AV_CODEC_FLAG2_*<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(14) 
	public int flags2() {
		return this.io.getIntField(this, 14);
	}
	/**
	 * AV_CODEC_FLAG2_*<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(14) 
	public AVCodecContext flags2(int flags2) {
		this.io.setIntField(this, 14, flags2);
		return this;
	}
	/**
	 * some codecs need / can use extradata like Huffman tables.<br>
	 * MJPEG: Huffman tables<br>
	 * rv10: additional flags<br>
	 * MPEG-4: global headers (they can be in the bitstream or here)<br>
	 * The allocated memory should be AV_INPUT_BUFFER_PADDING_SIZE bytes larger<br>
	 * than extradata_size to avoid problems if it is read with the bitstream reader.<br>
	 * The bytewise contents of extradata must not depend on the architecture or CPU endianness.<br>
	 * - encoding: Set/allocated/freed by libavcodec.<br>
	 * - decoding: Set/allocated/freed by user.<br>
	 * C type : uint8_t*
	 */
	@Field(15) 
	public Pointer<Byte > extradata() {
		return this.io.getPointerField(this, 15);
	}
	/**
	 * some codecs need / can use extradata like Huffman tables.<br>
	 * MJPEG: Huffman tables<br>
	 * rv10: additional flags<br>
	 * MPEG-4: global headers (they can be in the bitstream or here)<br>
	 * The allocated memory should be AV_INPUT_BUFFER_PADDING_SIZE bytes larger<br>
	 * than extradata_size to avoid problems if it is read with the bitstream reader.<br>
	 * The bytewise contents of extradata must not depend on the architecture or CPU endianness.<br>
	 * - encoding: Set/allocated/freed by libavcodec.<br>
	 * - decoding: Set/allocated/freed by user.<br>
	 * C type : uint8_t*
	 */
	@Field(15) 
	public AVCodecContext extradata(Pointer<Byte > extradata) {
		this.io.setPointerField(this, 15, extradata);
		return this;
	}
	@Field(16) 
	public int extradata_size() {
		return this.io.getIntField(this, 16);
	}
	@Field(16) 
	public AVCodecContext extradata_size(int extradata_size) {
		this.io.setIntField(this, 16, extradata_size);
		return this;
	}
	/**
	 * This is the fundamental unit of time (in seconds) in terms<br>
	 * of which frame timestamps are represented. For fixed-fps content,<br>
	 * timebase should be 1/framerate and timestamp increments should be<br>
	 * identically 1.<br>
	 * This often, but not always is the inverse of the frame rate or field rate<br>
	 * for video. 1/time_base is not the average frame rate if the frame rate is not<br>
	 * constant.<br>
	 * * Like containers, elementary streams also can store timestamps, 1/time_base<br>
	 * is the unit in which these timestamps are specified.<br>
	 * As example of such codec time base see ISO/IEC 14496-2:2001(E)<br>
	 * vop_time_increment_resolution and fixed_vop_rate<br>
	 * (fixed_vop_rate == 0 implies that it is different from the framerate)<br>
	 * * - encoding: MUST be set by user.<br>
	 * - decoding: the use of this field for decoding is deprecated.<br>
	 *             Use framerate instead.<br>
	 * C type : AVRational
	 */
	@Field(17) 
	public AVRational time_base() {
		return this.io.getNativeObjectField(this, 17);
	}
	/**
	 * This is the fundamental unit of time (in seconds) in terms<br>
	 * of which frame timestamps are represented. For fixed-fps content,<br>
	 * timebase should be 1/framerate and timestamp increments should be<br>
	 * identically 1.<br>
	 * This often, but not always is the inverse of the frame rate or field rate<br>
	 * for video. 1/time_base is not the average frame rate if the frame rate is not<br>
	 * constant.<br>
	 * * Like containers, elementary streams also can store timestamps, 1/time_base<br>
	 * is the unit in which these timestamps are specified.<br>
	 * As example of such codec time base see ISO/IEC 14496-2:2001(E)<br>
	 * vop_time_increment_resolution and fixed_vop_rate<br>
	 * (fixed_vop_rate == 0 implies that it is different from the framerate)<br>
	 * * - encoding: MUST be set by user.<br>
	 * - decoding: the use of this field for decoding is deprecated.<br>
	 *             Use framerate instead.<br>
	 * C type : AVRational
	 */
	@Field(17) 
	public AVCodecContext time_base(AVRational time_base) {
		this.io.setNativeObjectField(this, 17, time_base);
		return this;
	}
	/**
	 * For some codecs, the time base is closer to the field rate than the frame rate.<br>
	 * Most notably, H.264 and MPEG-2 specify time_base as half of frame duration<br>
	 * if no telecine is used ...<br>
	 * * Set to time_base ticks per frame. Default 1, e.g., H.264/MPEG-2 set it to 2.
	 */
	@Field(18) 
	public int ticks_per_frame() {
		return this.io.getIntField(this, 18);
	}
	/**
	 * For some codecs, the time base is closer to the field rate than the frame rate.<br>
	 * Most notably, H.264 and MPEG-2 specify time_base as half of frame duration<br>
	 * if no telecine is used ...<br>
	 * * Set to time_base ticks per frame. Default 1, e.g., H.264/MPEG-2 set it to 2.
	 */
	@Field(18) 
	public AVCodecContext ticks_per_frame(int ticks_per_frame) {
		this.io.setIntField(this, 18, ticks_per_frame);
		return this;
	}
	/**
	 * Codec delay.<br>
	 * * Encoding: Number of frames delay there will be from the encoder input to<br>
	 *           the decoder output. (we assume the decoder matches the spec)<br>
	 * Decoding: Number of frames delay in addition to what a standard decoder<br>
	 *           as specified in the spec would produce.<br>
	 * * Video:<br>
	 *   Number of frames the decoded output will be delayed relative to the<br>
	 *   encoded input.<br>
	 * * Audio:<br>
	 *   For encoding, this field is unused (see initial_padding).<br>
	 * *   For decoding, this is the number of samples the decoder needs to<br>
	 *   output before the decoder's output is valid. When seeking, you should<br>
	 *   start decoding this many samples prior to your desired seek point.<br>
	 * * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by libavcodec.
	 */
	@Field(19) 
	public int delay() {
		return this.io.getIntField(this, 19);
	}
	/**
	 * Codec delay.<br>
	 * * Encoding: Number of frames delay there will be from the encoder input to<br>
	 *           the decoder output. (we assume the decoder matches the spec)<br>
	 * Decoding: Number of frames delay in addition to what a standard decoder<br>
	 *           as specified in the spec would produce.<br>
	 * * Video:<br>
	 *   Number of frames the decoded output will be delayed relative to the<br>
	 *   encoded input.<br>
	 * * Audio:<br>
	 *   For encoding, this field is unused (see initial_padding).<br>
	 * *   For decoding, this is the number of samples the decoder needs to<br>
	 *   output before the decoder's output is valid. When seeking, you should<br>
	 *   start decoding this many samples prior to your desired seek point.<br>
	 * * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by libavcodec.
	 */
	@Field(19) 
	public AVCodecContext delay(int delay) {
		this.io.setIntField(this, 19, delay);
		return this;
	}
	/**
	 * picture width / height.<br>
	 * * @note Those fields may not match the values of the last<br>
	 * AVFrame output by avcodec_decode_video2 due frame<br>
	 * reordering.<br>
	 * * - encoding: MUST be set by user.<br>
	 * - decoding: May be set by the user before opening the decoder if known e.g.<br>
	 *             from the container. Some decoders will require the dimensions<br>
	 *             to be set by the caller. During decoding, the decoder may<br>
	 *             overwrite those values as required while parsing the data.
	 */
	@Field(20) 
	public int width() {
		return this.io.getIntField(this, 20);
	}
	/**
	 * picture width / height.<br>
	 * * @note Those fields may not match the values of the last<br>
	 * AVFrame output by avcodec_decode_video2 due frame<br>
	 * reordering.<br>
	 * * - encoding: MUST be set by user.<br>
	 * - decoding: May be set by the user before opening the decoder if known e.g.<br>
	 *             from the container. Some decoders will require the dimensions<br>
	 *             to be set by the caller. During decoding, the decoder may<br>
	 *             overwrite those values as required while parsing the data.
	 */
	@Field(20) 
	public AVCodecContext width(int width) {
		this.io.setIntField(this, 20, width);
		return this;
	}
	/**
	 * picture width / height.<br>
	 * * @note Those fields may not match the values of the last<br>
	 * AVFrame output by avcodec_decode_video2 due frame<br>
	 * reordering.<br>
	 * * - encoding: MUST be set by user.<br>
	 * - decoding: May be set by the user before opening the decoder if known e.g.<br>
	 *             from the container. Some decoders will require the dimensions<br>
	 *             to be set by the caller. During decoding, the decoder may<br>
	 *             overwrite those values as required while parsing the data.
	 */
	@Field(21) 
	public int height() {
		return this.io.getIntField(this, 21);
	}
	/**
	 * picture width / height.<br>
	 * * @note Those fields may not match the values of the last<br>
	 * AVFrame output by avcodec_decode_video2 due frame<br>
	 * reordering.<br>
	 * * - encoding: MUST be set by user.<br>
	 * - decoding: May be set by the user before opening the decoder if known e.g.<br>
	 *             from the container. Some decoders will require the dimensions<br>
	 *             to be set by the caller. During decoding, the decoder may<br>
	 *             overwrite those values as required while parsing the data.
	 */
	@Field(21) 
	public AVCodecContext height(int height) {
		this.io.setIntField(this, 21, height);
		return this;
	}
	/**
	 * Bitstream width / height, may be different from width/height e.g. when<br>
	 * the decoded frame is cropped before being output or lowres is enabled.<br>
	 * * @note Those field may not match the value of the last<br>
	 * AVFrame output by avcodec_receive_frame() due frame<br>
	 * reordering.<br>
	 * * - encoding: unused<br>
	 * - decoding: May be set by the user before opening the decoder if known<br>
	 *             e.g. from the container. During decoding, the decoder may<br>
	 *             overwrite those values as required while parsing the data.
	 */
	@Field(22) 
	public int coded_width() {
		return this.io.getIntField(this, 22);
	}
	/**
	 * Bitstream width / height, may be different from width/height e.g. when<br>
	 * the decoded frame is cropped before being output or lowres is enabled.<br>
	 * * @note Those field may not match the value of the last<br>
	 * AVFrame output by avcodec_receive_frame() due frame<br>
	 * reordering.<br>
	 * * - encoding: unused<br>
	 * - decoding: May be set by the user before opening the decoder if known<br>
	 *             e.g. from the container. During decoding, the decoder may<br>
	 *             overwrite those values as required while parsing the data.
	 */
	@Field(22) 
	public AVCodecContext coded_width(int coded_width) {
		this.io.setIntField(this, 22, coded_width);
		return this;
	}
	/**
	 * Bitstream width / height, may be different from width/height e.g. when<br>
	 * the decoded frame is cropped before being output or lowres is enabled.<br>
	 * * @note Those field may not match the value of the last<br>
	 * AVFrame output by avcodec_receive_frame() due frame<br>
	 * reordering.<br>
	 * * - encoding: unused<br>
	 * - decoding: May be set by the user before opening the decoder if known<br>
	 *             e.g. from the container. During decoding, the decoder may<br>
	 *             overwrite those values as required while parsing the data.
	 */
	@Field(23) 
	public int coded_height() {
		return this.io.getIntField(this, 23);
	}
	/**
	 * Bitstream width / height, may be different from width/height e.g. when<br>
	 * the decoded frame is cropped before being output or lowres is enabled.<br>
	 * * @note Those field may not match the value of the last<br>
	 * AVFrame output by avcodec_receive_frame() due frame<br>
	 * reordering.<br>
	 * * - encoding: unused<br>
	 * - decoding: May be set by the user before opening the decoder if known<br>
	 *             e.g. from the container. During decoding, the decoder may<br>
	 *             overwrite those values as required while parsing the data.
	 */
	@Field(23) 
	public AVCodecContext coded_height(int coded_height) {
		this.io.setIntField(this, 23, coded_height);
		return this;
	}
	/**
	 * the number of pictures in a group of pictures, or 0 for intra_only<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(24) 
	public int gop_size() {
		return this.io.getIntField(this, 24);
	}
	/**
	 * the number of pictures in a group of pictures, or 0 for intra_only<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(24) 
	public AVCodecContext gop_size(int gop_size) {
		this.io.setIntField(this, 24, gop_size);
		return this;
	}
	/**
	 * Pixel format, see AV_PIX_FMT_xxx.<br>
	 * May be set by the demuxer if known from headers.<br>
	 * May be overridden by the decoder if it knows better.<br>
	 * * @note This field may not match the value of the last<br>
	 * AVFrame output by avcodec_receive_frame() due frame<br>
	 * reordering.<br>
	 * * - encoding: Set by user.<br>
	 * - decoding: Set by user if known, overridden by libavcodec while<br>
	 *             parsing the data.<br>
	 * C type : AVPixelFormat
	 */
	@Field(25) 
	public IntValuedEnum<AVPixelFormat > pix_fmt() {
		return this.io.getEnumField(this, 25);
	}
	/**
	 * Pixel format, see AV_PIX_FMT_xxx.<br>
	 * May be set by the demuxer if known from headers.<br>
	 * May be overridden by the decoder if it knows better.<br>
	 * * @note This field may not match the value of the last<br>
	 * AVFrame output by avcodec_receive_frame() due frame<br>
	 * reordering.<br>
	 * * - encoding: Set by user.<br>
	 * - decoding: Set by user if known, overridden by libavcodec while<br>
	 *             parsing the data.<br>
	 * C type : AVPixelFormat
	 */
	@Field(25) 
	public AVCodecContext pix_fmt(IntValuedEnum<AVPixelFormat > pix_fmt) {
		this.io.setEnumField(this, 25, pix_fmt);
		return this;
	}
	/**
	 * If non NULL, 'draw_horiz_band' is called by the libavcodec<br>
	 * decoder to draw a horizontal band. It improves cache usage. Not<br>
	 * all codecs can do that. You must check the codec capabilities<br>
	 * beforehand.<br>
	 * When multithreading is used, it may be called from multiple threads<br>
	 * at the same time; threads might draw different parts of the same AVFrame,<br>
	 * or multiple AVFrames, and there is no guarantee that slices will be drawn<br>
	 * in order.<br>
	 * The function is also used by hardware acceleration APIs.<br>
	 * It is called at least once during frame decoding to pass<br>
	 * the data needed for hardware render.<br>
	 * In that mode instead of pixel data, AVFrame points to<br>
	 * a structure specific to the acceleration API. The application<br>
	 * reads the structure and can change some fields to indicate progress<br>
	 * or mark state.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.<br>
	 * @param height the height of the slice<br>
	 * @param y the y position of the slice<br>
	 * @param type 1->top field, 2->bottom field, 3->frame<br>
	 * @param offset offset into the AVFrame.data from which the slice should be read<br>
	 * C type : draw_horiz_band_callback*
	 */
	@Field(26) 
	public Pointer<AVCodecContext.draw_horiz_band_callback > draw_horiz_band() {
		return this.io.getPointerField(this, 26);
	}
	/**
	 * If non NULL, 'draw_horiz_band' is called by the libavcodec<br>
	 * decoder to draw a horizontal band. It improves cache usage. Not<br>
	 * all codecs can do that. You must check the codec capabilities<br>
	 * beforehand.<br>
	 * When multithreading is used, it may be called from multiple threads<br>
	 * at the same time; threads might draw different parts of the same AVFrame,<br>
	 * or multiple AVFrames, and there is no guarantee that slices will be drawn<br>
	 * in order.<br>
	 * The function is also used by hardware acceleration APIs.<br>
	 * It is called at least once during frame decoding to pass<br>
	 * the data needed for hardware render.<br>
	 * In that mode instead of pixel data, AVFrame points to<br>
	 * a structure specific to the acceleration API. The application<br>
	 * reads the structure and can change some fields to indicate progress<br>
	 * or mark state.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.<br>
	 * @param height the height of the slice<br>
	 * @param y the y position of the slice<br>
	 * @param type 1->top field, 2->bottom field, 3->frame<br>
	 * @param offset offset into the AVFrame.data from which the slice should be read<br>
	 * C type : draw_horiz_band_callback*
	 */
	@Field(26) 
	public AVCodecContext draw_horiz_band(Pointer<AVCodecContext.draw_horiz_band_callback > draw_horiz_band) {
		this.io.setPointerField(this, 26, draw_horiz_band);
		return this;
	}
	/**
	 * callback to negotiate the pixelFormat<br>
	 * @param fmt is the list of formats which are supported by the codec,<br>
	 * it is terminated by -1 as 0 is a valid format, the formats are ordered by quality.<br>
	 * The first is always the native one.<br>
	 * @note The callback may be called again immediately if initialization for<br>
	 * the selected (hardware-accelerated) pixel format failed.<br>
	 * @warning Behavior is undefined if the callback returns a value not<br>
	 * in the fmt list of formats.<br>
	 * @return the chosen format<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user, if not set the native format will be chosen.
	 */
	@CLong 
	@Field(27) 
	public long get_format() {
		return this.io.getCLongField(this, 27);
	}
	/**
	 * callback to negotiate the pixelFormat<br>
	 * @param fmt is the list of formats which are supported by the codec,<br>
	 * it is terminated by -1 as 0 is a valid format, the formats are ordered by quality.<br>
	 * The first is always the native one.<br>
	 * @note The callback may be called again immediately if initialization for<br>
	 * the selected (hardware-accelerated) pixel format failed.<br>
	 * @warning Behavior is undefined if the callback returns a value not<br>
	 * in the fmt list of formats.<br>
	 * @return the chosen format<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user, if not set the native format will be chosen.
	 */
	@CLong 
	@Field(27) 
	public AVCodecContext get_format(long get_format) {
		this.io.setCLongField(this, 27, get_format);
		return this;
	}
	/**
	 * maximum number of B-frames between non-B-frames<br>
	 * Note: The output will be delayed by max_b_frames+1 relative to the input.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(28) 
	public int max_b_frames() {
		return this.io.getIntField(this, 28);
	}
	/**
	 * maximum number of B-frames between non-B-frames<br>
	 * Note: The output will be delayed by max_b_frames+1 relative to the input.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(28) 
	public AVCodecContext max_b_frames(int max_b_frames) {
		this.io.setIntField(this, 28, max_b_frames);
		return this;
	}
	/**
	 * qscale factor between IP and B-frames<br>
	 * If > 0 then the last P-frame quantizer will be used (q= lastp_q*factor+offset).<br>
	 * If < 0 then normal ratecontrol will be done (q= -normal_q*factor+offset).<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(29) 
	public float b_quant_factor() {
		return this.io.getFloatField(this, 29);
	}
	/**
	 * qscale factor between IP and B-frames<br>
	 * If > 0 then the last P-frame quantizer will be used (q= lastp_q*factor+offset).<br>
	 * If < 0 then normal ratecontrol will be done (q= -normal_q*factor+offset).<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(29) 
	public AVCodecContext b_quant_factor(float b_quant_factor) {
		this.io.setFloatField(this, 29, b_quant_factor);
		return this;
	}
	@Field(30) 
	public int b_frame_strategy() {
		return this.io.getIntField(this, 30);
	}
	@Field(30) 
	public AVCodecContext b_frame_strategy(int b_frame_strategy) {
		this.io.setIntField(this, 30, b_frame_strategy);
		return this;
	}
	/**
	 * qscale offset between IP and B-frames<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(31) 
	public float b_quant_offset() {
		return this.io.getFloatField(this, 31);
	}
	/**
	 * qscale offset between IP and B-frames<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(31) 
	public AVCodecContext b_quant_offset(float b_quant_offset) {
		this.io.setFloatField(this, 31, b_quant_offset);
		return this;
	}
	/**
	 * Size of the frame reordering buffer in the decoder.<br>
	 * For MPEG-2 it is 1 IPB or 0 low delay IP.<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by libavcodec.
	 */
	@Field(32) 
	public int has_b_frames() {
		return this.io.getIntField(this, 32);
	}
	/**
	 * Size of the frame reordering buffer in the decoder.<br>
	 * For MPEG-2 it is 1 IPB or 0 low delay IP.<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by libavcodec.
	 */
	@Field(32) 
	public AVCodecContext has_b_frames(int has_b_frames) {
		this.io.setIntField(this, 32, has_b_frames);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(33) 
	public int mpeg_quant() {
		return this.io.getIntField(this, 33);
	}
	/** @deprecated use encoder private options instead */
	@Field(33) 
	public AVCodecContext mpeg_quant(int mpeg_quant) {
		this.io.setIntField(this, 33, mpeg_quant);
		return this;
	}
	/**
	 * qscale factor between P- and I-frames<br>
	 * If > 0 then the last P-frame quantizer will be used (q = lastp_q * factor + offset).<br>
	 * If < 0 then normal ratecontrol will be done (q= -normal_q*factor+offset).<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(34) 
	public float i_quant_factor() {
		return this.io.getFloatField(this, 34);
	}
	/**
	 * qscale factor between P- and I-frames<br>
	 * If > 0 then the last P-frame quantizer will be used (q = lastp_q * factor + offset).<br>
	 * If < 0 then normal ratecontrol will be done (q= -normal_q*factor+offset).<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(34) 
	public AVCodecContext i_quant_factor(float i_quant_factor) {
		this.io.setFloatField(this, 34, i_quant_factor);
		return this;
	}
	/**
	 * qscale offset between P and I-frames<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(35) 
	public float i_quant_offset() {
		return this.io.getFloatField(this, 35);
	}
	/**
	 * qscale offset between P and I-frames<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(35) 
	public AVCodecContext i_quant_offset(float i_quant_offset) {
		this.io.setFloatField(this, 35, i_quant_offset);
		return this;
	}
	/**
	 * luminance masking (0-> disabled)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(36) 
	public float lumi_masking() {
		return this.io.getFloatField(this, 36);
	}
	/**
	 * luminance masking (0-> disabled)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(36) 
	public AVCodecContext lumi_masking(float lumi_masking) {
		this.io.setFloatField(this, 36, lumi_masking);
		return this;
	}
	/**
	 * temporary complexity masking (0-> disabled)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(37) 
	public float temporal_cplx_masking() {
		return this.io.getFloatField(this, 37);
	}
	/**
	 * temporary complexity masking (0-> disabled)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(37) 
	public AVCodecContext temporal_cplx_masking(float temporal_cplx_masking) {
		this.io.setFloatField(this, 37, temporal_cplx_masking);
		return this;
	}
	/**
	 * spatial complexity masking (0-> disabled)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(38) 
	public float spatial_cplx_masking() {
		return this.io.getFloatField(this, 38);
	}
	/**
	 * spatial complexity masking (0-> disabled)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(38) 
	public AVCodecContext spatial_cplx_masking(float spatial_cplx_masking) {
		this.io.setFloatField(this, 38, spatial_cplx_masking);
		return this;
	}
	/**
	 * p block masking (0-> disabled)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(39) 
	public float p_masking() {
		return this.io.getFloatField(this, 39);
	}
	/**
	 * p block masking (0-> disabled)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(39) 
	public AVCodecContext p_masking(float p_masking) {
		this.io.setFloatField(this, 39, p_masking);
		return this;
	}
	/**
	 * darkness masking (0-> disabled)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(40) 
	public float dark_masking() {
		return this.io.getFloatField(this, 40);
	}
	/**
	 * darkness masking (0-> disabled)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(40) 
	public AVCodecContext dark_masking(float dark_masking) {
		this.io.setFloatField(this, 40, dark_masking);
		return this;
	}
	/**
	 * slice count<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by user (or 0).
	 */
	@Field(41) 
	public int slice_count() {
		return this.io.getIntField(this, 41);
	}
	/**
	 * slice count<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by user (or 0).
	 */
	@Field(41) 
	public AVCodecContext slice_count(int slice_count) {
		this.io.setIntField(this, 41, slice_count);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(42) 
	public int prediction_method() {
		return this.io.getIntField(this, 42);
	}
	/** @deprecated use encoder private options instead */
	@Field(42) 
	public AVCodecContext prediction_method(int prediction_method) {
		this.io.setIntField(this, 42, prediction_method);
		return this;
	}
	/**
	 * slice offsets in the frame in bytes<br>
	 * - encoding: Set/allocated by libavcodec.<br>
	 * - decoding: Set/allocated by user (or NULL).<br>
	 * C type : int*
	 */
	@Field(43) 
	public Pointer<Integer > slice_offset() {
		return this.io.getPointerField(this, 43);
	}
	/**
	 * slice offsets in the frame in bytes<br>
	 * - encoding: Set/allocated by libavcodec.<br>
	 * - decoding: Set/allocated by user (or NULL).<br>
	 * C type : int*
	 */
	@Field(43) 
	public AVCodecContext slice_offset(Pointer<Integer > slice_offset) {
		this.io.setPointerField(this, 43, slice_offset);
		return this;
	}
	/**
	 * sample aspect ratio (0 if unknown)<br>
	 * That is the width of a pixel divided by the height of the pixel.<br>
	 * Numerator and denominator must be relatively prime and smaller than 256 for some video standards.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : AVRational
	 */
	@Field(44) 
	public AVRational sample_aspect_ratio() {
		return this.io.getNativeObjectField(this, 44);
	}
	/**
	 * sample aspect ratio (0 if unknown)<br>
	 * That is the width of a pixel divided by the height of the pixel.<br>
	 * Numerator and denominator must be relatively prime and smaller than 256 for some video standards.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : AVRational
	 */
	@Field(44) 
	public AVCodecContext sample_aspect_ratio(AVRational sample_aspect_ratio) {
		this.io.setNativeObjectField(this, 44, sample_aspect_ratio);
		return this;
	}
	/**
	 * motion estimation comparison function<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(45) 
	public int me_cmp() {
		return this.io.getIntField(this, 45);
	}
	/**
	 * motion estimation comparison function<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(45) 
	public AVCodecContext me_cmp(int me_cmp) {
		this.io.setIntField(this, 45, me_cmp);
		return this;
	}
	/**
	 * subpixel motion estimation comparison function<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(46) 
	public int me_sub_cmp() {
		return this.io.getIntField(this, 46);
	}
	/**
	 * subpixel motion estimation comparison function<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(46) 
	public AVCodecContext me_sub_cmp(int me_sub_cmp) {
		this.io.setIntField(this, 46, me_sub_cmp);
		return this;
	}
	/**
	 * macroblock comparison function (not supported yet)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(47) 
	public int mb_cmp() {
		return this.io.getIntField(this, 47);
	}
	/**
	 * macroblock comparison function (not supported yet)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(47) 
	public AVCodecContext mb_cmp(int mb_cmp) {
		this.io.setIntField(this, 47, mb_cmp);
		return this;
	}
	/**
	 * interlaced DCT comparison function<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(48) 
	public int ildct_cmp() {
		return this.io.getIntField(this, 48);
	}
	/**
	 * interlaced DCT comparison function<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(48) 
	public AVCodecContext ildct_cmp(int ildct_cmp) {
		this.io.setIntField(this, 48, ildct_cmp);
		return this;
	}
	/**
	 * ME diamond size & shape<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(49) 
	public int dia_size() {
		return this.io.getIntField(this, 49);
	}
	/**
	 * ME diamond size & shape<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(49) 
	public AVCodecContext dia_size(int dia_size) {
		this.io.setIntField(this, 49, dia_size);
		return this;
	}
	/**
	 * amount of previous MV predictors (2a+1 x 2a+1 square)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(50) 
	public int last_predictor_count() {
		return this.io.getIntField(this, 50);
	}
	/**
	 * amount of previous MV predictors (2a+1 x 2a+1 square)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(50) 
	public AVCodecContext last_predictor_count(int last_predictor_count) {
		this.io.setIntField(this, 50, last_predictor_count);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(51) 
	public int pre_me() {
		return this.io.getIntField(this, 51);
	}
	/** @deprecated use encoder private options instead */
	@Field(51) 
	public AVCodecContext pre_me(int pre_me) {
		this.io.setIntField(this, 51, pre_me);
		return this;
	}
	/**
	 * motion estimation prepass comparison function<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(52) 
	public int me_pre_cmp() {
		return this.io.getIntField(this, 52);
	}
	/**
	 * motion estimation prepass comparison function<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(52) 
	public AVCodecContext me_pre_cmp(int me_pre_cmp) {
		this.io.setIntField(this, 52, me_pre_cmp);
		return this;
	}
	/**
	 * ME prepass diamond size & shape<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(53) 
	public int pre_dia_size() {
		return this.io.getIntField(this, 53);
	}
	/**
	 * ME prepass diamond size & shape<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(53) 
	public AVCodecContext pre_dia_size(int pre_dia_size) {
		this.io.setIntField(this, 53, pre_dia_size);
		return this;
	}
	/**
	 * subpel ME quality<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(54) 
	public int me_subpel_quality() {
		return this.io.getIntField(this, 54);
	}
	/**
	 * subpel ME quality<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(54) 
	public AVCodecContext me_subpel_quality(int me_subpel_quality) {
		this.io.setIntField(this, 54, me_subpel_quality);
		return this;
	}
	/**
	 * maximum motion estimation search range in subpel units<br>
	 * If 0 then no limit.<br>
	 * * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(55) 
	public int me_range() {
		return this.io.getIntField(this, 55);
	}
	/**
	 * maximum motion estimation search range in subpel units<br>
	 * If 0 then no limit.<br>
	 * * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(55) 
	public AVCodecContext me_range(int me_range) {
		this.io.setIntField(this, 55, me_range);
		return this;
	}
	/**
	 * slice flags<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(56) 
	public int slice_flags() {
		return this.io.getIntField(this, 56);
	}
	/**
	 * slice flags<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(56) 
	public AVCodecContext slice_flags(int slice_flags) {
		this.io.setIntField(this, 56, slice_flags);
		return this;
	}
	/**
	 * macroblock decision mode<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(57) 
	public int mb_decision() {
		return this.io.getIntField(this, 57);
	}
	/**
	 * macroblock decision mode<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(57) 
	public AVCodecContext mb_decision(int mb_decision) {
		this.io.setIntField(this, 57, mb_decision);
		return this;
	}
	/**
	 * custom intra quantization matrix<br>
	 * - encoding: Set by user, can be NULL.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : uint16_t*
	 */
	@Field(58) 
	public Pointer<Short > intra_matrix() {
		return this.io.getPointerField(this, 58);
	}
	/**
	 * custom intra quantization matrix<br>
	 * - encoding: Set by user, can be NULL.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : uint16_t*
	 */
	@Field(58) 
	public AVCodecContext intra_matrix(Pointer<Short > intra_matrix) {
		this.io.setPointerField(this, 58, intra_matrix);
		return this;
	}
	/**
	 * custom inter quantization matrix<br>
	 * - encoding: Set by user, can be NULL.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : uint16_t*
	 */
	@Field(59) 
	public Pointer<Short > inter_matrix() {
		return this.io.getPointerField(this, 59);
	}
	/**
	 * custom inter quantization matrix<br>
	 * - encoding: Set by user, can be NULL.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : uint16_t*
	 */
	@Field(59) 
	public AVCodecContext inter_matrix(Pointer<Short > inter_matrix) {
		this.io.setPointerField(this, 59, inter_matrix);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(60) 
	public int scenechange_threshold() {
		return this.io.getIntField(this, 60);
	}
	/** @deprecated use encoder private options instead */
	@Field(60) 
	public AVCodecContext scenechange_threshold(int scenechange_threshold) {
		this.io.setIntField(this, 60, scenechange_threshold);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(61) 
	public int noise_reduction() {
		return this.io.getIntField(this, 61);
	}
	/** @deprecated use encoder private options instead */
	@Field(61) 
	public AVCodecContext noise_reduction(int noise_reduction) {
		this.io.setIntField(this, 61, noise_reduction);
		return this;
	}
	/**
	 * precision of the intra DC coefficient - 8<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec
	 */
	@Field(62) 
	public int intra_dc_precision() {
		return this.io.getIntField(this, 62);
	}
	/**
	 * precision of the intra DC coefficient - 8<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec
	 */
	@Field(62) 
	public AVCodecContext intra_dc_precision(int intra_dc_precision) {
		this.io.setIntField(this, 62, intra_dc_precision);
		return this;
	}
	/**
	 * Number of macroblock rows at the top which are skipped.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(63) 
	public int skip_top() {
		return this.io.getIntField(this, 63);
	}
	/**
	 * Number of macroblock rows at the top which are skipped.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(63) 
	public AVCodecContext skip_top(int skip_top) {
		this.io.setIntField(this, 63, skip_top);
		return this;
	}
	/**
	 * Number of macroblock rows at the bottom which are skipped.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(64) 
	public int skip_bottom() {
		return this.io.getIntField(this, 64);
	}
	/**
	 * Number of macroblock rows at the bottom which are skipped.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(64) 
	public AVCodecContext skip_bottom(int skip_bottom) {
		this.io.setIntField(this, 64, skip_bottom);
		return this;
	}
	/**
	 * minimum MB Lagrange multiplier<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(65) 
	public int mb_lmin() {
		return this.io.getIntField(this, 65);
	}
	/**
	 * minimum MB Lagrange multiplier<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(65) 
	public AVCodecContext mb_lmin(int mb_lmin) {
		this.io.setIntField(this, 65, mb_lmin);
		return this;
	}
	/**
	 * maximum MB Lagrange multiplier<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(66) 
	public int mb_lmax() {
		return this.io.getIntField(this, 66);
	}
	/**
	 * maximum MB Lagrange multiplier<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(66) 
	public AVCodecContext mb_lmax(int mb_lmax) {
		this.io.setIntField(this, 66, mb_lmax);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(67) 
	public int me_penalty_compensation() {
		return this.io.getIntField(this, 67);
	}
	/** @deprecated use encoder private options instead */
	@Field(67) 
	public AVCodecContext me_penalty_compensation(int me_penalty_compensation) {
		this.io.setIntField(this, 67, me_penalty_compensation);
		return this;
	}
	/**
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(68) 
	public int bidir_refine() {
		return this.io.getIntField(this, 68);
	}
	/**
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(68) 
	public AVCodecContext bidir_refine(int bidir_refine) {
		this.io.setIntField(this, 68, bidir_refine);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(69) 
	public int brd_scale() {
		return this.io.getIntField(this, 69);
	}
	/** @deprecated use encoder private options instead */
	@Field(69) 
	public AVCodecContext brd_scale(int brd_scale) {
		this.io.setIntField(this, 69, brd_scale);
		return this;
	}
	/**
	 * minimum GOP size<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(70) 
	public int keyint_min() {
		return this.io.getIntField(this, 70);
	}
	/**
	 * minimum GOP size<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(70) 
	public AVCodecContext keyint_min(int keyint_min) {
		this.io.setIntField(this, 70, keyint_min);
		return this;
	}
	/**
	 * number of reference frames<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by lavc.
	 */
	@Field(71) 
	public int refs() {
		return this.io.getIntField(this, 71);
	}
	/**
	 * number of reference frames<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by lavc.
	 */
	@Field(71) 
	public AVCodecContext refs(int refs) {
		this.io.setIntField(this, 71, refs);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(72) 
	public int chromaoffset() {
		return this.io.getIntField(this, 72);
	}
	/** @deprecated use encoder private options instead */
	@Field(72) 
	public AVCodecContext chromaoffset(int chromaoffset) {
		this.io.setIntField(this, 72, chromaoffset);
		return this;
	}
	/**
	 * Note: Value depends upon the compare function used for fullpel ME.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(73) 
	public int mv0_threshold() {
		return this.io.getIntField(this, 73);
	}
	/**
	 * Note: Value depends upon the compare function used for fullpel ME.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(73) 
	public AVCodecContext mv0_threshold(int mv0_threshold) {
		this.io.setIntField(this, 73, mv0_threshold);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(74) 
	public int b_sensitivity() {
		return this.io.getIntField(this, 74);
	}
	/** @deprecated use encoder private options instead */
	@Field(74) 
	public AVCodecContext b_sensitivity(int b_sensitivity) {
		this.io.setIntField(this, 74, b_sensitivity);
		return this;
	}
	/**
	 * Chromaticity coordinates of the source primaries.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorPrimaries
	 */
	@Field(75) 
	public IntValuedEnum<AVColorPrimaries > color_primaries() {
		return this.io.getEnumField(this, 75);
	}
	/**
	 * Chromaticity coordinates of the source primaries.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorPrimaries
	 */
	@Field(75) 
	public AVCodecContext color_primaries(IntValuedEnum<AVColorPrimaries > color_primaries) {
		this.io.setEnumField(this, 75, color_primaries);
		return this;
	}
	/**
	 * Color Transfer Characteristic.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorTransferCharacteristic
	 */
	@Field(76) 
	public IntValuedEnum<AVColorTransferCharacteristic > color_trc() {
		return this.io.getEnumField(this, 76);
	}
	/**
	 * Color Transfer Characteristic.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorTransferCharacteristic
	 */
	@Field(76) 
	public AVCodecContext color_trc(IntValuedEnum<AVColorTransferCharacteristic > color_trc) {
		this.io.setEnumField(this, 76, color_trc);
		return this;
	}
	/**
	 * YUV colorspace type.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorSpace
	 */
	@Field(77) 
	public IntValuedEnum<AVColorSpace > colorspace() {
		return this.io.getEnumField(this, 77);
	}
	/**
	 * YUV colorspace type.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorSpace
	 */
	@Field(77) 
	public AVCodecContext colorspace(IntValuedEnum<AVColorSpace > colorspace) {
		this.io.setEnumField(this, 77, colorspace);
		return this;
	}
	/**
	 * MPEG vs JPEG YUV range.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorRange
	 */
	@Field(78) 
	public IntValuedEnum<AVColorRange > color_range() {
		return this.io.getEnumField(this, 78);
	}
	/**
	 * MPEG vs JPEG YUV range.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorRange
	 */
	@Field(78) 
	public AVCodecContext color_range(IntValuedEnum<AVColorRange > color_range) {
		this.io.setEnumField(this, 78, color_range);
		return this;
	}
	/**
	 * This defines the location of chroma samples.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVChromaLocation
	 */
	@Field(79) 
	public IntValuedEnum<AVChromaLocation > chroma_sample_location() {
		return this.io.getEnumField(this, 79);
	}
	/**
	 * This defines the location of chroma samples.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVChromaLocation
	 */
	@Field(79) 
	public AVCodecContext chroma_sample_location(IntValuedEnum<AVChromaLocation > chroma_sample_location) {
		this.io.setEnumField(this, 79, chroma_sample_location);
		return this;
	}
	/**
	 * Number of slices.<br>
	 * Indicates number of picture subdivisions. Used for parallelized<br>
	 * decoding.<br>
	 * - encoding: Set by user<br>
	 * - decoding: unused
	 */
	@Field(80) 
	public int slices() {
		return this.io.getIntField(this, 80);
	}
	/**
	 * Number of slices.<br>
	 * Indicates number of picture subdivisions. Used for parallelized<br>
	 * decoding.<br>
	 * - encoding: Set by user<br>
	 * - decoding: unused
	 */
	@Field(80) 
	public AVCodecContext slices(int slices) {
		this.io.setIntField(this, 80, slices);
		return this;
	}
	/**
	 * Field order<br>
	 * - encoding: set by libavcodec<br>
	 * - decoding: Set by user.<br>
	 * C type : AVFieldOrder
	 */
	@Field(81) 
	public IntValuedEnum<AVFieldOrder > field_order() {
		return this.io.getEnumField(this, 81);
	}
	/**
	 * Field order<br>
	 * - encoding: set by libavcodec<br>
	 * - decoding: Set by user.<br>
	 * C type : AVFieldOrder
	 */
	@Field(81) 
	public AVCodecContext field_order(IntValuedEnum<AVFieldOrder > field_order) {
		this.io.setEnumField(this, 81, field_order);
		return this;
	}
	/**
	 * audio only<br>
	 * < samples per second
	 */
	@Field(82) 
	public int sample_rate() {
		return this.io.getIntField(this, 82);
	}
	/**
	 * audio only<br>
	 * < samples per second
	 */
	@Field(82) 
	public AVCodecContext sample_rate(int sample_rate) {
		this.io.setIntField(this, 82, sample_rate);
		return this;
	}
	/** < number of audio channels */
	@Field(83) 
	public int channels() {
		return this.io.getIntField(this, 83);
	}
	/** < number of audio channels */
	@Field(83) 
	public AVCodecContext channels(int channels) {
		this.io.setIntField(this, 83, channels);
		return this;
	}
	/**
	 * audio sample format<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * < sample format<br>
	 * C type : AVSampleFormat
	 */
	@Field(84) 
	public IntValuedEnum<AVSampleFormat > sample_fmt() {
		return this.io.getEnumField(this, 84);
	}
	/**
	 * audio sample format<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * < sample format<br>
	 * C type : AVSampleFormat
	 */
	@Field(84) 
	public AVCodecContext sample_fmt(IntValuedEnum<AVSampleFormat > sample_fmt) {
		this.io.setEnumField(this, 84, sample_fmt);
		return this;
	}
	/**
	 * Number of samples per channel in an audio frame.<br>
	 * * - encoding: set by libavcodec in avcodec_open2(). Each submitted frame<br>
	 *   except the last must contain exactly frame_size samples per channel.<br>
	 *   May be 0 when the codec has AV_CODEC_CAP_VARIABLE_FRAME_SIZE set, then the<br>
	 *   frame size is not restricted.<br>
	 * - decoding: may be set by some decoders to indicate constant frame size
	 */
	@Field(85) 
	public int frame_size() {
		return this.io.getIntField(this, 85);
	}
	/**
	 * Number of samples per channel in an audio frame.<br>
	 * * - encoding: set by libavcodec in avcodec_open2(). Each submitted frame<br>
	 *   except the last must contain exactly frame_size samples per channel.<br>
	 *   May be 0 when the codec has AV_CODEC_CAP_VARIABLE_FRAME_SIZE set, then the<br>
	 *   frame size is not restricted.<br>
	 * - decoding: may be set by some decoders to indicate constant frame size
	 */
	@Field(85) 
	public AVCodecContext frame_size(int frame_size) {
		this.io.setIntField(this, 85, frame_size);
		return this;
	}
	/**
	 * Frame counter, set by libavcodec.<br>
	 * * - decoding: total number of frames returned from the decoder so far.<br>
	 * - encoding: total number of frames passed to the encoder so far.<br>
	 * *   @note the counter is not incremented if encoding/decoding resulted in<br>
	 *   an error.
	 */
	@Field(86) 
	public int frame_number() {
		return this.io.getIntField(this, 86);
	}
	/**
	 * Frame counter, set by libavcodec.<br>
	 * * - decoding: total number of frames returned from the decoder so far.<br>
	 * - encoding: total number of frames passed to the encoder so far.<br>
	 * *   @note the counter is not incremented if encoding/decoding resulted in<br>
	 *   an error.
	 */
	@Field(86) 
	public AVCodecContext frame_number(int frame_number) {
		this.io.setIntField(this, 86, frame_number);
		return this;
	}
	/**
	 * number of bytes per packet if constant and known or 0<br>
	 * Used by some WAV based audio codecs.
	 */
	@Field(87) 
	public int block_align() {
		return this.io.getIntField(this, 87);
	}
	/**
	 * number of bytes per packet if constant and known or 0<br>
	 * Used by some WAV based audio codecs.
	 */
	@Field(87) 
	public AVCodecContext block_align(int block_align) {
		this.io.setIntField(this, 87, block_align);
		return this;
	}
	/**
	 * Audio cutoff bandwidth (0 means "automatic")<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(88) 
	public int cutoff() {
		return this.io.getIntField(this, 88);
	}
	/**
	 * Audio cutoff bandwidth (0 means "automatic")<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(88) 
	public AVCodecContext cutoff(int cutoff) {
		this.io.setIntField(this, 88, cutoff);
		return this;
	}
	/**
	 * Audio channel layout.<br>
	 * - encoding: set by user.<br>
	 * - decoding: set by user, may be overwritten by libavcodec.
	 */
	@Field(89) 
	public long channel_layout() {
		return this.io.getLongField(this, 89);
	}
	/**
	 * Audio channel layout.<br>
	 * - encoding: set by user.<br>
	 * - decoding: set by user, may be overwritten by libavcodec.
	 */
	@Field(89) 
	public AVCodecContext channel_layout(long channel_layout) {
		this.io.setLongField(this, 89, channel_layout);
		return this;
	}
	/**
	 * Request decoder to use this channel layout if it can (0 for default)<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(90) 
	public long request_channel_layout() {
		return this.io.getLongField(this, 90);
	}
	/**
	 * Request decoder to use this channel layout if it can (0 for default)<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(90) 
	public AVCodecContext request_channel_layout(long request_channel_layout) {
		this.io.setLongField(this, 90, request_channel_layout);
		return this;
	}
	/**
	 * Type of service that the audio stream conveys.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : AVAudioServiceType
	 */
	@Field(91) 
	public IntValuedEnum<AVAudioServiceType > audio_service_type() {
		return this.io.getEnumField(this, 91);
	}
	/**
	 * Type of service that the audio stream conveys.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : AVAudioServiceType
	 */
	@Field(91) 
	public AVCodecContext audio_service_type(IntValuedEnum<AVAudioServiceType > audio_service_type) {
		this.io.setEnumField(this, 91, audio_service_type);
		return this;
	}
	/**
	 * desired sample format<br>
	 * - encoding: Not used.<br>
	 * - decoding: Set by user.<br>
	 * Decoder will decode to this format if it can.<br>
	 * C type : AVSampleFormat
	 */
	@Field(92) 
	public IntValuedEnum<AVSampleFormat > request_sample_fmt() {
		return this.io.getEnumField(this, 92);
	}
	/**
	 * desired sample format<br>
	 * - encoding: Not used.<br>
	 * - decoding: Set by user.<br>
	 * Decoder will decode to this format if it can.<br>
	 * C type : AVSampleFormat
	 */
	@Field(92) 
	public AVCodecContext request_sample_fmt(IntValuedEnum<AVSampleFormat > request_sample_fmt) {
		this.io.setEnumField(this, 92, request_sample_fmt);
		return this;
	}
	/**
	 * This callback is called at the beginning of each frame to get data<br>
	 * buffer(s) for it. There may be one contiguous buffer for all the data or<br>
	 * there may be a buffer per each data plane or anything in between. What<br>
	 * this means is, you may set however many entries in buf[] you feel necessary.<br>
	 * Each buffer must be reference-counted using the AVBuffer API (see description<br>
	 * of buf[] below).<br>
	 * * The following fields will be set in the frame before this callback is<br>
	 * called:<br>
	 * - format<br>
	 * - width, height (video only)<br>
	 * - sample_rate, channel_layout, nb_samples (audio only)<br>
	 * Their values may differ from the corresponding values in<br>
	 * AVCodecContext. This callback must use the frame values, not the codec<br>
	 * context values, to calculate the required buffer size.<br>
	 * * This callback must fill the following fields in the frame:<br>
	 * - data[]<br>
	 * - linesize[]<br>
	 * - extended_data:<br>
	 *   * if the data is planar audio with more than 8 channels, then this<br>
	 *     callback must allocate and fill extended_data to contain all pointers<br>
	 *     to all data planes. data[] must hold as many pointers as it can.<br>
	 *     extended_data must be allocated with av_malloc() and will be freed in<br>
	 *     av_frame_unref().<br>
	 *   * otherwise extended_data must point to data<br>
	 * - buf[] must contain one or more pointers to AVBufferRef structures. Each of<br>
	 *   the frame's data and extended_data pointers must be contained in these. That<br>
	 *   is, one AVBufferRef for each allocated chunk of memory, not necessarily one<br>
	 *   AVBufferRef per data[] entry. See: av_buffer_create(), av_buffer_alloc(),<br>
	 *   and av_buffer_ref().<br>
	 * - extended_buf and nb_extended_buf must be allocated with av_malloc() by<br>
	 *   this callback and filled with the extra buffers if there are more<br>
	 *   buffers than buf[] can hold. extended_buf will be freed in<br>
	 *   av_frame_unref().<br>
	 * * If AV_CODEC_CAP_DR1 is not set then get_buffer2() must call<br>
	 * avcodec_default_get_buffer2() instead of providing buffers allocated by<br>
	 * some other means.<br>
	 * * Each data plane must be aligned to the maximum required by the target<br>
	 * CPU.<br>
	 * * @see avcodec_default_get_buffer2()<br>
	 * * Video:<br>
	 * * If AV_GET_BUFFER_FLAG_REF is set in flags then the frame may be reused<br>
	 * (read and/or written to if it is writable) later by libavcodec.<br>
	 * * avcodec_align_dimensions2() should be used to find the required width and<br>
	 * height, as they normally need to be rounded up to the next multiple of 16.<br>
	 * * Some decoders do not support linesizes changing between frames.<br>
	 * * If frame multithreading is used and thread_safe_callbacks is set,<br>
	 * this callback may be called from a different thread, but not from more<br>
	 * than one at once. Does not need to be reentrant.<br>
	 * * @see avcodec_align_dimensions2()<br>
	 * * Audio:<br>
	 * * Decoders request a buffer of a particular size by setting<br>
	 * AVFrame.nb_samples prior to calling get_buffer2(). The decoder may,<br>
	 * however, utilize only part of the buffer by setting AVFrame.nb_samples<br>
	 * to a smaller value in the output frame.<br>
	 * * As a convenience, av_samples_get_buffer_size() and<br>
	 * av_samples_fill_arrays() in libavutil may be used by custom get_buffer2()<br>
	 * functions to find the required data size and to fill data pointers and<br>
	 * linesize. In AVFrame.linesize, only linesize[0] may be set for audio<br>
	 * since all planes must be the same size.<br>
	 * * @see av_samples_get_buffer_size(), av_samples_fill_arrays()<br>
	 * * - encoding: unused<br>
	 * - decoding: Set by libavcodec, user can override.<br>
	 * C type : get_buffer2_callback*
	 */
	@Field(93) 
	public Pointer<AVCodecContext.get_buffer2_callback > get_buffer2() {
		return this.io.getPointerField(this, 93);
	}
	/**
	 * This callback is called at the beginning of each frame to get data<br>
	 * buffer(s) for it. There may be one contiguous buffer for all the data or<br>
	 * there may be a buffer per each data plane or anything in between. What<br>
	 * this means is, you may set however many entries in buf[] you feel necessary.<br>
	 * Each buffer must be reference-counted using the AVBuffer API (see description<br>
	 * of buf[] below).<br>
	 * * The following fields will be set in the frame before this callback is<br>
	 * called:<br>
	 * - format<br>
	 * - width, height (video only)<br>
	 * - sample_rate, channel_layout, nb_samples (audio only)<br>
	 * Their values may differ from the corresponding values in<br>
	 * AVCodecContext. This callback must use the frame values, not the codec<br>
	 * context values, to calculate the required buffer size.<br>
	 * * This callback must fill the following fields in the frame:<br>
	 * - data[]<br>
	 * - linesize[]<br>
	 * - extended_data:<br>
	 *   * if the data is planar audio with more than 8 channels, then this<br>
	 *     callback must allocate and fill extended_data to contain all pointers<br>
	 *     to all data planes. data[] must hold as many pointers as it can.<br>
	 *     extended_data must be allocated with av_malloc() and will be freed in<br>
	 *     av_frame_unref().<br>
	 *   * otherwise extended_data must point to data<br>
	 * - buf[] must contain one or more pointers to AVBufferRef structures. Each of<br>
	 *   the frame's data and extended_data pointers must be contained in these. That<br>
	 *   is, one AVBufferRef for each allocated chunk of memory, not necessarily one<br>
	 *   AVBufferRef per data[] entry. See: av_buffer_create(), av_buffer_alloc(),<br>
	 *   and av_buffer_ref().<br>
	 * - extended_buf and nb_extended_buf must be allocated with av_malloc() by<br>
	 *   this callback and filled with the extra buffers if there are more<br>
	 *   buffers than buf[] can hold. extended_buf will be freed in<br>
	 *   av_frame_unref().<br>
	 * * If AV_CODEC_CAP_DR1 is not set then get_buffer2() must call<br>
	 * avcodec_default_get_buffer2() instead of providing buffers allocated by<br>
	 * some other means.<br>
	 * * Each data plane must be aligned to the maximum required by the target<br>
	 * CPU.<br>
	 * * @see avcodec_default_get_buffer2()<br>
	 * * Video:<br>
	 * * If AV_GET_BUFFER_FLAG_REF is set in flags then the frame may be reused<br>
	 * (read and/or written to if it is writable) later by libavcodec.<br>
	 * * avcodec_align_dimensions2() should be used to find the required width and<br>
	 * height, as they normally need to be rounded up to the next multiple of 16.<br>
	 * * Some decoders do not support linesizes changing between frames.<br>
	 * * If frame multithreading is used and thread_safe_callbacks is set,<br>
	 * this callback may be called from a different thread, but not from more<br>
	 * than one at once. Does not need to be reentrant.<br>
	 * * @see avcodec_align_dimensions2()<br>
	 * * Audio:<br>
	 * * Decoders request a buffer of a particular size by setting<br>
	 * AVFrame.nb_samples prior to calling get_buffer2(). The decoder may,<br>
	 * however, utilize only part of the buffer by setting AVFrame.nb_samples<br>
	 * to a smaller value in the output frame.<br>
	 * * As a convenience, av_samples_get_buffer_size() and<br>
	 * av_samples_fill_arrays() in libavutil may be used by custom get_buffer2()<br>
	 * functions to find the required data size and to fill data pointers and<br>
	 * linesize. In AVFrame.linesize, only linesize[0] may be set for audio<br>
	 * since all planes must be the same size.<br>
	 * * @see av_samples_get_buffer_size(), av_samples_fill_arrays()<br>
	 * * - encoding: unused<br>
	 * - decoding: Set by libavcodec, user can override.<br>
	 * C type : get_buffer2_callback*
	 */
	@Field(93) 
	public AVCodecContext get_buffer2(Pointer<AVCodecContext.get_buffer2_callback > get_buffer2) {
		this.io.setPointerField(this, 93, get_buffer2);
		return this;
	}
	/**
	 * If non-zero, the decoded audio and video frames returned from<br>
	 * avcodec_decode_video2() and avcodec_decode_audio4() are reference-counted<br>
	 * and are valid indefinitely. The caller must free them with<br>
	 * av_frame_unref() when they are not needed anymore.<br>
	 * Otherwise, the decoded frames must not be freed by the caller and are<br>
	 * only valid until the next decode call.<br>
	 * * This is always automatically enabled if avcodec_receive_frame() is used.<br>
	 * * - encoding: unused<br>
	 * - decoding: set by the caller before avcodec_open2().
	 */
	@Field(94) 
	public int refcounted_frames() {
		return this.io.getIntField(this, 94);
	}
	/**
	 * If non-zero, the decoded audio and video frames returned from<br>
	 * avcodec_decode_video2() and avcodec_decode_audio4() are reference-counted<br>
	 * and are valid indefinitely. The caller must free them with<br>
	 * av_frame_unref() when they are not needed anymore.<br>
	 * Otherwise, the decoded frames must not be freed by the caller and are<br>
	 * only valid until the next decode call.<br>
	 * * This is always automatically enabled if avcodec_receive_frame() is used.<br>
	 * * - encoding: unused<br>
	 * - decoding: set by the caller before avcodec_open2().
	 */
	@Field(94) 
	public AVCodecContext refcounted_frames(int refcounted_frames) {
		this.io.setIntField(this, 94, refcounted_frames);
		return this;
	}
	/**
	 * - encoding parameters<br>
	 * < amount of qscale change between easy & hard scenes (0.0-1.0)
	 */
	@Field(95) 
	public float qcompress() {
		return this.io.getFloatField(this, 95);
	}
	/**
	 * - encoding parameters<br>
	 * < amount of qscale change between easy & hard scenes (0.0-1.0)
	 */
	@Field(95) 
	public AVCodecContext qcompress(float qcompress) {
		this.io.setFloatField(this, 95, qcompress);
		return this;
	}
	/** < amount of qscale smoothing over time (0.0-1.0) */
	@Field(96) 
	public float qblur() {
		return this.io.getFloatField(this, 96);
	}
	/** < amount of qscale smoothing over time (0.0-1.0) */
	@Field(96) 
	public AVCodecContext qblur(float qblur) {
		this.io.setFloatField(this, 96, qblur);
		return this;
	}
	/**
	 * minimum quantizer<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(97) 
	public int qmin() {
		return this.io.getIntField(this, 97);
	}
	/**
	 * minimum quantizer<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(97) 
	public AVCodecContext qmin(int qmin) {
		this.io.setIntField(this, 97, qmin);
		return this;
	}
	/**
	 * maximum quantizer<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(98) 
	public int qmax() {
		return this.io.getIntField(this, 98);
	}
	/**
	 * maximum quantizer<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(98) 
	public AVCodecContext qmax(int qmax) {
		this.io.setIntField(this, 98, qmax);
		return this;
	}
	/**
	 * maximum quantizer difference between frames<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(99) 
	public int max_qdiff() {
		return this.io.getIntField(this, 99);
	}
	/**
	 * maximum quantizer difference between frames<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(99) 
	public AVCodecContext max_qdiff(int max_qdiff) {
		this.io.setIntField(this, 99, max_qdiff);
		return this;
	}
	/**
	 * decoder bitstream buffer size<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(100) 
	public int rc_buffer_size() {
		return this.io.getIntField(this, 100);
	}
	/**
	 * decoder bitstream buffer size<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(100) 
	public AVCodecContext rc_buffer_size(int rc_buffer_size) {
		this.io.setIntField(this, 100, rc_buffer_size);
		return this;
	}
	/**
	 * ratecontrol override, see RcOverride<br>
	 * - encoding: Allocated/set/freed by user.<br>
	 * - decoding: unused
	 */
	@Field(101) 
	public int rc_override_count() {
		return this.io.getIntField(this, 101);
	}
	/**
	 * ratecontrol override, see RcOverride<br>
	 * - encoding: Allocated/set/freed by user.<br>
	 * - decoding: unused
	 */
	@Field(101) 
	public AVCodecContext rc_override_count(int rc_override_count) {
		this.io.setIntField(this, 101, rc_override_count);
		return this;
	}
	/** C type : RcOverride* */
	@Field(102) 
	public Pointer<RcOverride > rc_override() {
		return this.io.getPointerField(this, 102);
	}
	/** C type : RcOverride* */
	@Field(102) 
	public AVCodecContext rc_override(Pointer<RcOverride > rc_override) {
		this.io.setPointerField(this, 102, rc_override);
		return this;
	}
	/**
	 * maximum bitrate<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user, may be overwritten by libavcodec.
	 */
	@Field(103) 
	public long rc_max_rate() {
		return this.io.getLongField(this, 103);
	}
	/**
	 * maximum bitrate<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user, may be overwritten by libavcodec.
	 */
	@Field(103) 
	public AVCodecContext rc_max_rate(long rc_max_rate) {
		this.io.setLongField(this, 103, rc_max_rate);
		return this;
	}
	/**
	 * minimum bitrate<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(104) 
	public long rc_min_rate() {
		return this.io.getLongField(this, 104);
	}
	/**
	 * minimum bitrate<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(104) 
	public AVCodecContext rc_min_rate(long rc_min_rate) {
		this.io.setLongField(this, 104, rc_min_rate);
		return this;
	}
	/**
	 * Ratecontrol attempt to use, at maximum, <value> of what can be used without an underflow.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused.
	 */
	@Field(105) 
	public float rc_max_available_vbv_use() {
		return this.io.getFloatField(this, 105);
	}
	/**
	 * Ratecontrol attempt to use, at maximum, <value> of what can be used without an underflow.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused.
	 */
	@Field(105) 
	public AVCodecContext rc_max_available_vbv_use(float rc_max_available_vbv_use) {
		this.io.setFloatField(this, 105, rc_max_available_vbv_use);
		return this;
	}
	/**
	 * Ratecontrol attempt to use, at least, <value> times the amount needed to prevent a vbv overflow.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused.
	 */
	@Field(106) 
	public float rc_min_vbv_overflow_use() {
		return this.io.getFloatField(this, 106);
	}
	/**
	 * Ratecontrol attempt to use, at least, <value> times the amount needed to prevent a vbv overflow.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused.
	 */
	@Field(106) 
	public AVCodecContext rc_min_vbv_overflow_use(float rc_min_vbv_overflow_use) {
		this.io.setFloatField(this, 106, rc_min_vbv_overflow_use);
		return this;
	}
	/**
	 * Number of bits which should be loaded into the rc buffer before decoding starts.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(107) 
	public int rc_initial_buffer_occupancy() {
		return this.io.getIntField(this, 107);
	}
	/**
	 * Number of bits which should be loaded into the rc buffer before decoding starts.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(107) 
	public AVCodecContext rc_initial_buffer_occupancy(int rc_initial_buffer_occupancy) {
		this.io.setIntField(this, 107, rc_initial_buffer_occupancy);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(108) 
	public int coder_type() {
		return this.io.getIntField(this, 108);
	}
	/** @deprecated use encoder private options instead */
	@Field(108) 
	public AVCodecContext coder_type(int coder_type) {
		this.io.setIntField(this, 108, coder_type);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(109) 
	public int context_model() {
		return this.io.getIntField(this, 109);
	}
	/** @deprecated use encoder private options instead */
	@Field(109) 
	public AVCodecContext context_model(int context_model) {
		this.io.setIntField(this, 109, context_model);
		return this;
	}
	@Field(110) 
	public int frame_skip_threshold() {
		return this.io.getIntField(this, 110);
	}
	@Field(110) 
	public AVCodecContext frame_skip_threshold(int frame_skip_threshold) {
		this.io.setIntField(this, 110, frame_skip_threshold);
		return this;
	}
	@Field(111) 
	public int frame_skip_factor() {
		return this.io.getIntField(this, 111);
	}
	@Field(111) 
	public AVCodecContext frame_skip_factor(int frame_skip_factor) {
		this.io.setIntField(this, 111, frame_skip_factor);
		return this;
	}
	@Field(112) 
	public int frame_skip_exp() {
		return this.io.getIntField(this, 112);
	}
	@Field(112) 
	public AVCodecContext frame_skip_exp(int frame_skip_exp) {
		this.io.setIntField(this, 112, frame_skip_exp);
		return this;
	}
	@Field(113) 
	public int frame_skip_cmp() {
		return this.io.getIntField(this, 113);
	}
	@Field(113) 
	public AVCodecContext frame_skip_cmp(int frame_skip_cmp) {
		this.io.setIntField(this, 113, frame_skip_cmp);
		return this;
	}
	/**
	 * trellis RD quantization<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(114) 
	public int trellis() {
		return this.io.getIntField(this, 114);
	}
	/**
	 * trellis RD quantization<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(114) 
	public AVCodecContext trellis(int trellis) {
		this.io.setIntField(this, 114, trellis);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(115) 
	public int min_prediction_order() {
		return this.io.getIntField(this, 115);
	}
	/** @deprecated use encoder private options instead */
	@Field(115) 
	public AVCodecContext min_prediction_order(int min_prediction_order) {
		this.io.setIntField(this, 115, min_prediction_order);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(116) 
	public int max_prediction_order() {
		return this.io.getIntField(this, 116);
	}
	/** @deprecated use encoder private options instead */
	@Field(116) 
	public AVCodecContext max_prediction_order(int max_prediction_order) {
		this.io.setIntField(this, 116, max_prediction_order);
		return this;
	}
	/** @deprecated use encoder private options instead */
	@Field(117) 
	public long timecode_frame_start() {
		return this.io.getLongField(this, 117);
	}
	/** @deprecated use encoder private options instead */
	@Field(117) 
	public AVCodecContext timecode_frame_start(long timecode_frame_start) {
		this.io.setLongField(this, 117, timecode_frame_start);
		return this;
	}
	/**
	 * encoded in the RTP payload.<br>
	 * C type : rtp_callback_callback*
	 */
	@Field(118) 
	public Pointer<AVCodecContext.rtp_callback_callback > rtp_callback() {
		return this.io.getPointerField(this, 118);
	}
	/**
	 * encoded in the RTP payload.<br>
	 * C type : rtp_callback_callback*
	 */
	@Field(118) 
	public AVCodecContext rtp_callback(Pointer<AVCodecContext.rtp_callback_callback > rtp_callback) {
		this.io.setPointerField(this, 118, rtp_callback);
		return this;
	}
	/**
	 * @deprecated use encoder private options instead<br>
	 * The size of the RTP payload: the coder will
	 */
	@Field(119) 
	public int rtp_payload_size() {
		return this.io.getIntField(this, 119);
	}
	/**
	 * @deprecated use encoder private options instead<br>
	 * The size of the RTP payload: the coder will
	 */
	@Field(119) 
	public AVCodecContext rtp_payload_size(int rtp_payload_size) {
		this.io.setIntField(this, 119, rtp_payload_size);
		return this;
	}
	/** statistics, used for 2-pass encoding */
	@Field(120) 
	public int mv_bits() {
		return this.io.getIntField(this, 120);
	}
	/** statistics, used for 2-pass encoding */
	@Field(120) 
	public AVCodecContext mv_bits(int mv_bits) {
		this.io.setIntField(this, 120, mv_bits);
		return this;
	}
	@Field(121) 
	public int header_bits() {
		return this.io.getIntField(this, 121);
	}
	@Field(121) 
	public AVCodecContext header_bits(int header_bits) {
		this.io.setIntField(this, 121, header_bits);
		return this;
	}
	@Field(122) 
	public int i_tex_bits() {
		return this.io.getIntField(this, 122);
	}
	@Field(122) 
	public AVCodecContext i_tex_bits(int i_tex_bits) {
		this.io.setIntField(this, 122, i_tex_bits);
		return this;
	}
	@Field(123) 
	public int p_tex_bits() {
		return this.io.getIntField(this, 123);
	}
	@Field(123) 
	public AVCodecContext p_tex_bits(int p_tex_bits) {
		this.io.setIntField(this, 123, p_tex_bits);
		return this;
	}
	@Field(124) 
	public int i_count() {
		return this.io.getIntField(this, 124);
	}
	@Field(124) 
	public AVCodecContext i_count(int i_count) {
		this.io.setIntField(this, 124, i_count);
		return this;
	}
	@Field(125) 
	public int p_count() {
		return this.io.getIntField(this, 125);
	}
	@Field(125) 
	public AVCodecContext p_count(int p_count) {
		this.io.setIntField(this, 125, p_count);
		return this;
	}
	@Field(126) 
	public int skip_count() {
		return this.io.getIntField(this, 126);
	}
	@Field(126) 
	public AVCodecContext skip_count(int skip_count) {
		this.io.setIntField(this, 126, skip_count);
		return this;
	}
	@Field(127) 
	public int misc_bits() {
		return this.io.getIntField(this, 127);
	}
	@Field(127) 
	public AVCodecContext misc_bits(int misc_bits) {
		this.io.setIntField(this, 127, misc_bits);
		return this;
	}
	/** @deprecated this field is unused */
	@Field(128) 
	public int frame_bits() {
		return this.io.getIntField(this, 128);
	}
	/** @deprecated this field is unused */
	@Field(128) 
	public AVCodecContext frame_bits(int frame_bits) {
		this.io.setIntField(this, 128, frame_bits);
		return this;
	}
	/**
	 * pass1 encoding statistics output buffer<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: unused<br>
	 * C type : char*
	 */
	@Field(129) 
	public Pointer<Byte > stats_out() {
		return this.io.getPointerField(this, 129);
	}
	/**
	 * pass1 encoding statistics output buffer<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: unused<br>
	 * C type : char*
	 */
	@Field(129) 
	public AVCodecContext stats_out(Pointer<Byte > stats_out) {
		this.io.setPointerField(this, 129, stats_out);
		return this;
	}
	/**
	 * pass2 encoding statistics input buffer<br>
	 * Concatenated stuff from stats_out of pass1 should be placed here.<br>
	 * - encoding: Allocated/set/freed by user.<br>
	 * - decoding: unused<br>
	 * C type : char*
	 */
	@Field(130) 
	public Pointer<Byte > stats_in() {
		return this.io.getPointerField(this, 130);
	}
	/**
	 * pass2 encoding statistics input buffer<br>
	 * Concatenated stuff from stats_out of pass1 should be placed here.<br>
	 * - encoding: Allocated/set/freed by user.<br>
	 * - decoding: unused<br>
	 * C type : char*
	 */
	@Field(130) 
	public AVCodecContext stats_in(Pointer<Byte > stats_in) {
		this.io.setPointerField(this, 130, stats_in);
		return this;
	}
	/**
	 * Work around bugs in encoders which sometimes cannot be detected automatically.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by user
	 */
	@Field(131) 
	public int workaround_bugs() {
		return this.io.getIntField(this, 131);
	}
	/**
	 * Work around bugs in encoders which sometimes cannot be detected automatically.<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by user
	 */
	@Field(131) 
	public AVCodecContext workaround_bugs(int workaround_bugs) {
		this.io.setIntField(this, 131, workaround_bugs);
		return this;
	}
	/**
	 * strictly follow the standard (MPEG-4, ...).<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.<br>
	 * Setting this to STRICT or higher means the encoder and decoder will<br>
	 * generally do stupid things, whereas setting it to unofficial or lower<br>
	 * will mean the encoder might produce output that is not supported by all<br>
	 * spec-compliant decoders. Decoders don't differentiate between normal,<br>
	 * unofficial and experimental (that is, they always try to decode things<br>
	 * when they can) unless they are explicitly asked to behave stupidly<br>
	 * (=strictly conform to the specs)
	 */
	@Field(132) 
	public int strict_std_compliance() {
		return this.io.getIntField(this, 132);
	}
	/**
	 * strictly follow the standard (MPEG-4, ...).<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.<br>
	 * Setting this to STRICT or higher means the encoder and decoder will<br>
	 * generally do stupid things, whereas setting it to unofficial or lower<br>
	 * will mean the encoder might produce output that is not supported by all<br>
	 * spec-compliant decoders. Decoders don't differentiate between normal,<br>
	 * unofficial and experimental (that is, they always try to decode things<br>
	 * when they can) unless they are explicitly asked to behave stupidly<br>
	 * (=strictly conform to the specs)
	 */
	@Field(132) 
	public AVCodecContext strict_std_compliance(int strict_std_compliance) {
		this.io.setIntField(this, 132, strict_std_compliance);
		return this;
	}
	/**
	 * error concealment flags<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(133) 
	public int error_concealment() {
		return this.io.getIntField(this, 133);
	}
	/**
	 * error concealment flags<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(133) 
	public AVCodecContext error_concealment(int error_concealment) {
		this.io.setIntField(this, 133, error_concealment);
		return this;
	}
	/**
	 * debug<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(134) 
	public int debug() {
		return this.io.getIntField(this, 134);
	}
	/**
	 * debug<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(134) 
	public AVCodecContext debug(int debug) {
		this.io.setIntField(this, 134, debug);
		return this;
	}
	/**
	 * Error recognition; may misdetect some more or less valid parts as errors.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(135) 
	public int err_recognition() {
		return this.io.getIntField(this, 135);
	}
	/**
	 * Error recognition; may misdetect some more or less valid parts as errors.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(135) 
	public AVCodecContext err_recognition(int err_recognition) {
		this.io.setIntField(this, 135, err_recognition);
		return this;
	}
	/**
	 * opaque 64-bit number (generally a PTS) that will be reordered and<br>
	 * output in AVFrame.reordered_opaque<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(136) 
	public long reordered_opaque() {
		return this.io.getLongField(this, 136);
	}
	/**
	 * opaque 64-bit number (generally a PTS) that will be reordered and<br>
	 * output in AVFrame.reordered_opaque<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(136) 
	public AVCodecContext reordered_opaque(long reordered_opaque) {
		this.io.setLongField(this, 136, reordered_opaque);
		return this;
	}
	/**
	 * Hardware accelerator in use<br>
	 * - encoding: unused.<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVHWAccel*
	 */
	@Field(137) 
	public Pointer<AVHWAccel > hwaccel() {
		return this.io.getPointerField(this, 137);
	}
	/**
	 * Hardware accelerator in use<br>
	 * - encoding: unused.<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVHWAccel*
	 */
	@Field(137) 
	public AVCodecContext hwaccel(Pointer<AVHWAccel > hwaccel) {
		this.io.setPointerField(this, 137, hwaccel);
		return this;
	}
	/**
	 * Hardware accelerator context.<br>
	 * For some hardware accelerators, a global context needs to be<br>
	 * provided by the user. In that case, this holds display-dependent<br>
	 * data FFmpeg cannot instantiate itself. Please refer to the<br>
	 * FFmpeg HW accelerator documentation to know how to fill this<br>
	 * is. e.g. for VA API, this is a struct vaapi_context.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user<br>
	 * C type : void*
	 */
	@Field(138) 
	public Pointer<? > hwaccel_context() {
		return this.io.getPointerField(this, 138);
	}
	/**
	 * Hardware accelerator context.<br>
	 * For some hardware accelerators, a global context needs to be<br>
	 * provided by the user. In that case, this holds display-dependent<br>
	 * data FFmpeg cannot instantiate itself. Please refer to the<br>
	 * FFmpeg HW accelerator documentation to know how to fill this<br>
	 * is. e.g. for VA API, this is a struct vaapi_context.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user<br>
	 * C type : void*
	 */
	@Field(138) 
	public AVCodecContext hwaccel_context(Pointer<? > hwaccel_context) {
		this.io.setPointerField(this, 138, hwaccel_context);
		return this;
	}
	/**
	 * error<br>
	 * - encoding: Set by libavcodec if flags & AV_CODEC_FLAG_PSNR.<br>
	 * - decoding: unused<br>
	 * C type : uint64_t[8]
	 */
	@Array({8}) 
	@Field(139) 
	public Pointer<Long > error() {
		return this.io.getPointerField(this, 139);
	}
	/**
	 * DCT algorithm, see FF_DCT_* below<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(140) 
	public int dct_algo() {
		return this.io.getIntField(this, 140);
	}
	/**
	 * DCT algorithm, see FF_DCT_* below<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(140) 
	public AVCodecContext dct_algo(int dct_algo) {
		this.io.setIntField(this, 140, dct_algo);
		return this;
	}
	/**
	 * IDCT algorithm, see FF_IDCT_* below.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(141) 
	public int idct_algo() {
		return this.io.getIntField(this, 141);
	}
	/**
	 * IDCT algorithm, see FF_IDCT_* below.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(141) 
	public AVCodecContext idct_algo(int idct_algo) {
		this.io.setIntField(this, 141, idct_algo);
		return this;
	}
	/**
	 * bits per sample/pixel from the demuxer (needed for huffyuv).<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by user.
	 */
	@Field(142) 
	public int bits_per_coded_sample() {
		return this.io.getIntField(this, 142);
	}
	/**
	 * bits per sample/pixel from the demuxer (needed for huffyuv).<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by user.
	 */
	@Field(142) 
	public AVCodecContext bits_per_coded_sample(int bits_per_coded_sample) {
		this.io.setIntField(this, 142, bits_per_coded_sample);
		return this;
	}
	/**
	 * Bits per sample/pixel of internal libavcodec pixel/sample format.<br>
	 * - encoding: set by user.<br>
	 * - decoding: set by libavcodec.
	 */
	@Field(143) 
	public int bits_per_raw_sample() {
		return this.io.getIntField(this, 143);
	}
	/**
	 * Bits per sample/pixel of internal libavcodec pixel/sample format.<br>
	 * - encoding: set by user.<br>
	 * - decoding: set by libavcodec.
	 */
	@Field(143) 
	public AVCodecContext bits_per_raw_sample(int bits_per_raw_sample) {
		this.io.setIntField(this, 143, bits_per_raw_sample);
		return this;
	}
	/**
	 * low resolution decoding, 1-> 1/2 size, 2->1/4 size<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(144) 
	public int lowres() {
		return this.io.getIntField(this, 144);
	}
	/**
	 * low resolution decoding, 1-> 1/2 size, 2->1/4 size<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	@Field(144) 
	public AVCodecContext lowres(int lowres) {
		this.io.setIntField(this, 144, lowres);
		return this;
	}
	/**
	 * the picture in the bitstream<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: unused<br>
	 * * @deprecated use the quality factor packet side data instead<br>
	 * C type : AVFrame*
	 */
	@Field(145) 
	public Pointer<AVFrame > coded_frame() {
		return this.io.getPointerField(this, 145);
	}
	/**
	 * the picture in the bitstream<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: unused<br>
	 * * @deprecated use the quality factor packet side data instead<br>
	 * C type : AVFrame*
	 */
	@Field(145) 
	public AVCodecContext coded_frame(Pointer<AVFrame > coded_frame) {
		this.io.setPointerField(this, 145, coded_frame);
		return this;
	}
	/**
	 * thread count<br>
	 * is used to decide how many independent tasks should be passed to execute()<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(146) 
	public int thread_count() {
		return this.io.getIntField(this, 146);
	}
	/**
	 * thread count<br>
	 * is used to decide how many independent tasks should be passed to execute()<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(146) 
	public AVCodecContext thread_count(int thread_count) {
		this.io.setIntField(this, 146, thread_count);
		return this;
	}
	/**
	 * Which multithreading methods to use.<br>
	 * Use of FF_THREAD_FRAME will increase decoding delay by one frame per thread,<br>
	 * so clients which cannot provide future frames should not use it.<br>
	 * * - encoding: Set by user, otherwise the default is used.<br>
	 * - decoding: Set by user, otherwise the default is used.
	 */
	@Field(147) 
	public int thread_type() {
		return this.io.getIntField(this, 147);
	}
	/**
	 * Which multithreading methods to use.<br>
	 * Use of FF_THREAD_FRAME will increase decoding delay by one frame per thread,<br>
	 * so clients which cannot provide future frames should not use it.<br>
	 * * - encoding: Set by user, otherwise the default is used.<br>
	 * - decoding: Set by user, otherwise the default is used.
	 */
	@Field(147) 
	public AVCodecContext thread_type(int thread_type) {
		this.io.setIntField(this, 147, thread_type);
		return this;
	}
	/**
	 * Which multithreading methods are in use by the codec.<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by libavcodec.
	 */
	@Field(148) 
	public int active_thread_type() {
		return this.io.getIntField(this, 148);
	}
	/**
	 * Which multithreading methods are in use by the codec.<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by libavcodec.
	 */
	@Field(148) 
	public AVCodecContext active_thread_type(int active_thread_type) {
		this.io.setIntField(this, 148, active_thread_type);
		return this;
	}
	/**
	 * Set by the client if its custom get_buffer() callback can be called<br>
	 * synchronously from another thread, which allows faster multithreaded decoding.<br>
	 * draw_horiz_band() will be called from other threads regardless of this setting.<br>
	 * Ignored if the default get_buffer() is used.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(149) 
	public int thread_safe_callbacks() {
		return this.io.getIntField(this, 149);
	}
	/**
	 * Set by the client if its custom get_buffer() callback can be called<br>
	 * synchronously from another thread, which allows faster multithreaded decoding.<br>
	 * draw_horiz_band() will be called from other threads regardless of this setting.<br>
	 * Ignored if the default get_buffer() is used.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(149) 
	public AVCodecContext thread_safe_callbacks(int thread_safe_callbacks) {
		this.io.setIntField(this, 149, thread_safe_callbacks);
		return this;
	}
	/**
	 * The codec may call this to execute several independent things.<br>
	 * It will return only after finishing all tasks.<br>
	 * The user may replace this with some multithreaded implementation,<br>
	 * the default implementation will execute the parts serially.<br>
	 * @param count the number of things to execute<br>
	 * - encoding: Set by libavcodec, user can override.<br>
	 * - decoding: Set by libavcodec, user can override.<br>
	 * C type : execute_callback*
	 */
	@Field(150) 
	public Pointer<AVCodecContext.execute_callback > execute() {
		return this.io.getPointerField(this, 150);
	}
	/**
	 * The codec may call this to execute several independent things.<br>
	 * It will return only after finishing all tasks.<br>
	 * The user may replace this with some multithreaded implementation,<br>
	 * the default implementation will execute the parts serially.<br>
	 * @param count the number of things to execute<br>
	 * - encoding: Set by libavcodec, user can override.<br>
	 * - decoding: Set by libavcodec, user can override.<br>
	 * C type : execute_callback*
	 */
	@Field(150) 
	public AVCodecContext execute(Pointer<AVCodecContext.execute_callback > execute) {
		this.io.setPointerField(this, 150, execute);
		return this;
	}
	/**
	 * The codec may call this to execute several independent things.<br>
	 * It will return only after finishing all tasks.<br>
	 * The user may replace this with some multithreaded implementation,<br>
	 * the default implementation will execute the parts serially.<br>
	 * Also see avcodec_thread_init and e.g. the --enable-pthread configure option.<br>
	 * @param c context passed also to func<br>
	 * @param count the number of things to execute<br>
	 * @param arg2 argument passed unchanged to func<br>
	 * @param ret return values of executed functions, must have space for "count" values. May be NULL.<br>
	 * @param func function that will be called count times, with jobnr from 0 to count-1.<br>
	 *             threadnr will be in the range 0 to c->thread_count-1 < MAX_THREADS and so that no<br>
	 *             two instances of func executing at the same time will have the same threadnr.<br>
	 * @return always 0 currently, but code should handle a future improvement where when any call to func<br>
	 *         returns < 0 no further calls to func may be done and < 0 is returned.<br>
	 * - encoding: Set by libavcodec, user can override.<br>
	 * - decoding: Set by libavcodec, user can override.<br>
	 * C type : execute2_callback*
	 */
	@Field(151) 
	public Pointer<AVCodecContext.execute2_callback > execute2() {
		return this.io.getPointerField(this, 151);
	}
	/**
	 * The codec may call this to execute several independent things.<br>
	 * It will return only after finishing all tasks.<br>
	 * The user may replace this with some multithreaded implementation,<br>
	 * the default implementation will execute the parts serially.<br>
	 * Also see avcodec_thread_init and e.g. the --enable-pthread configure option.<br>
	 * @param c context passed also to func<br>
	 * @param count the number of things to execute<br>
	 * @param arg2 argument passed unchanged to func<br>
	 * @param ret return values of executed functions, must have space for "count" values. May be NULL.<br>
	 * @param func function that will be called count times, with jobnr from 0 to count-1.<br>
	 *             threadnr will be in the range 0 to c->thread_count-1 < MAX_THREADS and so that no<br>
	 *             two instances of func executing at the same time will have the same threadnr.<br>
	 * @return always 0 currently, but code should handle a future improvement where when any call to func<br>
	 *         returns < 0 no further calls to func may be done and < 0 is returned.<br>
	 * - encoding: Set by libavcodec, user can override.<br>
	 * - decoding: Set by libavcodec, user can override.<br>
	 * C type : execute2_callback*
	 */
	@Field(151) 
	public AVCodecContext execute2(Pointer<AVCodecContext.execute2_callback > execute2) {
		this.io.setPointerField(this, 151, execute2);
		return this;
	}
	/**
	 * noise vs. sse weight for the nsse comparison function<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(152) 
	public int nsse_weight() {
		return this.io.getIntField(this, 152);
	}
	/**
	 * noise vs. sse weight for the nsse comparison function<br>
	 * - encoding: Set by user.<br>
	 * - decoding: unused
	 */
	@Field(152) 
	public AVCodecContext nsse_weight(int nsse_weight) {
		this.io.setIntField(this, 152, nsse_weight);
		return this;
	}
	/**
	 * profile<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.
	 */
	@Field(153) 
	public int profile() {
		return this.io.getIntField(this, 153);
	}
	/**
	 * profile<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.
	 */
	@Field(153) 
	public AVCodecContext profile(int profile) {
		this.io.setIntField(this, 153, profile);
		return this;
	}
	/**
	 * level<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.
	 */
	@Field(154) 
	public int level() {
		return this.io.getIntField(this, 154);
	}
	/**
	 * level<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.
	 */
	@Field(154) 
	public AVCodecContext level(int level) {
		this.io.setIntField(this, 154, level);
		return this;
	}
	/**
	 * Skip loop filtering for selected frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.<br>
	 * C type : AVDiscard
	 */
	@Field(155) 
	public IntValuedEnum<AVDiscard > skip_loop_filter() {
		return this.io.getEnumField(this, 155);
	}
	/**
	 * Skip loop filtering for selected frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.<br>
	 * C type : AVDiscard
	 */
	@Field(155) 
	public AVCodecContext skip_loop_filter(IntValuedEnum<AVDiscard > skip_loop_filter) {
		this.io.setEnumField(this, 155, skip_loop_filter);
		return this;
	}
	/**
	 * Skip IDCT/dequantization for selected frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.<br>
	 * C type : AVDiscard
	 */
	@Field(156) 
	public IntValuedEnum<AVDiscard > skip_idct() {
		return this.io.getEnumField(this, 156);
	}
	/**
	 * Skip IDCT/dequantization for selected frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.<br>
	 * C type : AVDiscard
	 */
	@Field(156) 
	public AVCodecContext skip_idct(IntValuedEnum<AVDiscard > skip_idct) {
		this.io.setEnumField(this, 156, skip_idct);
		return this;
	}
	/**
	 * Skip decoding for selected frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.<br>
	 * C type : AVDiscard
	 */
	@Field(157) 
	public IntValuedEnum<AVDiscard > skip_frame() {
		return this.io.getEnumField(this, 157);
	}
	/**
	 * Skip decoding for selected frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.<br>
	 * C type : AVDiscard
	 */
	@Field(157) 
	public AVCodecContext skip_frame(IntValuedEnum<AVDiscard > skip_frame) {
		this.io.setEnumField(this, 157, skip_frame);
		return this;
	}
	/**
	 * Header containing style information for text subtitles.<br>
	 * For SUBTITLE_ASS subtitle type, it should contain the whole ASS<br>
	 * [Script Info] and [V4+ Styles] section, plus the [Events] line and<br>
	 * the Format line following. It shouldn't include any Dialogue line.<br>
	 * - encoding: Set/allocated/freed by user (before avcodec_open2())<br>
	 * - decoding: Set/allocated/freed by libavcodec (by avcodec_open2())<br>
	 * C type : uint8_t*
	 */
	@Field(158) 
	public Pointer<Byte > subtitle_header() {
		return this.io.getPointerField(this, 158);
	}
	/**
	 * Header containing style information for text subtitles.<br>
	 * For SUBTITLE_ASS subtitle type, it should contain the whole ASS<br>
	 * [Script Info] and [V4+ Styles] section, plus the [Events] line and<br>
	 * the Format line following. It shouldn't include any Dialogue line.<br>
	 * - encoding: Set/allocated/freed by user (before avcodec_open2())<br>
	 * - decoding: Set/allocated/freed by libavcodec (by avcodec_open2())<br>
	 * C type : uint8_t*
	 */
	@Field(158) 
	public AVCodecContext subtitle_header(Pointer<Byte > subtitle_header) {
		this.io.setPointerField(this, 158, subtitle_header);
		return this;
	}
	@Field(159) 
	public int subtitle_header_size() {
		return this.io.getIntField(this, 159);
	}
	@Field(159) 
	public AVCodecContext subtitle_header_size(int subtitle_header_size) {
		this.io.setIntField(this, 159, subtitle_header_size);
		return this;
	}
	/**
	 * VBV delay coded in the last frame (in periods of a 27 MHz clock).<br>
	 * Used for compliant TS muxing.<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: unused.<br>
	 * @deprecated this value is now exported as a part of<br>
	 * AV_PKT_DATA_CPB_PROPERTIES packet side data
	 */
	@Field(160) 
	public long vbv_delay() {
		return this.io.getLongField(this, 160);
	}
	/**
	 * VBV delay coded in the last frame (in periods of a 27 MHz clock).<br>
	 * Used for compliant TS muxing.<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: unused.<br>
	 * @deprecated this value is now exported as a part of<br>
	 * AV_PKT_DATA_CPB_PROPERTIES packet side data
	 */
	@Field(160) 
	public AVCodecContext vbv_delay(long vbv_delay) {
		this.io.setLongField(this, 160, vbv_delay);
		return this;
	}
	/**
	 * Encoding only and set by default. Allow encoders to output packets<br>
	 * that do not contain any encoded data, only side data.<br>
	 * * Some encoders need to output such packets, e.g. to update some stream<br>
	 * parameters at the end of encoding.<br>
	 * * @deprecated this field disables the default behaviour and<br>
	 *             it is kept only for compatibility.
	 */
	@Field(161) 
	public int side_data_only_packets() {
		return this.io.getIntField(this, 161);
	}
	/**
	 * Encoding only and set by default. Allow encoders to output packets<br>
	 * that do not contain any encoded data, only side data.<br>
	 * * Some encoders need to output such packets, e.g. to update some stream<br>
	 * parameters at the end of encoding.<br>
	 * * @deprecated this field disables the default behaviour and<br>
	 *             it is kept only for compatibility.
	 */
	@Field(161) 
	public AVCodecContext side_data_only_packets(int side_data_only_packets) {
		this.io.setIntField(this, 161, side_data_only_packets);
		return this;
	}
	/**
	 * Audio only. The number of "priming" samples (padding) inserted by the<br>
	 * encoder at the beginning of the audio. I.e. this number of leading<br>
	 * decoded samples must be discarded by the caller to get the original audio<br>
	 * without leading padding.<br>
	 * * - decoding: unused<br>
	 * - encoding: Set by libavcodec. The timestamps on the output packets are<br>
	 *             adjusted by the encoder so that they always refer to the<br>
	 *             first sample of the data actually contained in the packet,<br>
	 *             including any added padding.  E.g. if the timebase is<br>
	 *             1/samplerate and the timestamp of the first input sample is<br>
	 *             0, the timestamp of the first output packet will be<br>
	 *             -initial_padding.
	 */
	@Field(162) 
	public int initial_padding() {
		return this.io.getIntField(this, 162);
	}
	/**
	 * Audio only. The number of "priming" samples (padding) inserted by the<br>
	 * encoder at the beginning of the audio. I.e. this number of leading<br>
	 * decoded samples must be discarded by the caller to get the original audio<br>
	 * without leading padding.<br>
	 * * - decoding: unused<br>
	 * - encoding: Set by libavcodec. The timestamps on the output packets are<br>
	 *             adjusted by the encoder so that they always refer to the<br>
	 *             first sample of the data actually contained in the packet,<br>
	 *             including any added padding.  E.g. if the timebase is<br>
	 *             1/samplerate and the timestamp of the first input sample is<br>
	 *             0, the timestamp of the first output packet will be<br>
	 *             -initial_padding.
	 */
	@Field(162) 
	public AVCodecContext initial_padding(int initial_padding) {
		this.io.setIntField(this, 162, initial_padding);
		return this;
	}
	/**
	 * - decoding: For codecs that store a framerate value in the compressed<br>
	 *             bitstream, the decoder may export it here. { 0, 1} when<br>
	 *             unknown.<br>
	 * - encoding: May be used to signal the framerate of CFR content to an<br>
	 *             encoder.<br>
	 * C type : AVRational
	 */
	@Field(163) 
	public AVRational framerate() {
		return this.io.getNativeObjectField(this, 163);
	}
	/**
	 * - decoding: For codecs that store a framerate value in the compressed<br>
	 *             bitstream, the decoder may export it here. { 0, 1} when<br>
	 *             unknown.<br>
	 * - encoding: May be used to signal the framerate of CFR content to an<br>
	 *             encoder.<br>
	 * C type : AVRational
	 */
	@Field(163) 
	public AVCodecContext framerate(AVRational framerate) {
		this.io.setNativeObjectField(this, 163, framerate);
		return this;
	}
	/**
	 * Nominal unaccelerated pixel format, see AV_PIX_FMT_xxx.<br>
	 * - encoding: unused.<br>
	 * - decoding: Set by libavcodec before calling get_format()<br>
	 * C type : AVPixelFormat
	 */
	@Field(164) 
	public IntValuedEnum<AVPixelFormat > sw_pix_fmt() {
		return this.io.getEnumField(this, 164);
	}
	/**
	 * Nominal unaccelerated pixel format, see AV_PIX_FMT_xxx.<br>
	 * - encoding: unused.<br>
	 * - decoding: Set by libavcodec before calling get_format()<br>
	 * C type : AVPixelFormat
	 */
	@Field(164) 
	public AVCodecContext sw_pix_fmt(IntValuedEnum<AVPixelFormat > sw_pix_fmt) {
		this.io.setEnumField(this, 164, sw_pix_fmt);
		return this;
	}
	/**
	 * Timebase in which pkt_dts/pts and AVPacket.dts/pts are.<br>
	 * - encoding unused.<br>
	 * - decoding set by user.<br>
	 * C type : AVRational
	 */
	@Field(165) 
	public AVRational pkt_timebase() {
		return this.io.getNativeObjectField(this, 165);
	}
	/**
	 * Timebase in which pkt_dts/pts and AVPacket.dts/pts are.<br>
	 * - encoding unused.<br>
	 * - decoding set by user.<br>
	 * C type : AVRational
	 */
	@Field(165) 
	public AVCodecContext pkt_timebase(AVRational pkt_timebase) {
		this.io.setNativeObjectField(this, 165, pkt_timebase);
		return this;
	}
	/**
	 * AVCodecDescriptor<br>
	 * - encoding: unused.<br>
	 * - decoding: set by libavcodec.<br>
	 * C type : const AVCodecDescriptor*
	 */
	@Field(166) 
	public Pointer<AVCodecDescriptor > codec_descriptor() {
		return this.io.getPointerField(this, 166);
	}
	/**
	 * AVCodecDescriptor<br>
	 * - encoding: unused.<br>
	 * - decoding: set by libavcodec.<br>
	 * C type : const AVCodecDescriptor*
	 */
	@Field(166) 
	public AVCodecContext codec_descriptor(Pointer<AVCodecDescriptor > codec_descriptor) {
		this.io.setPointerField(this, 166, codec_descriptor);
		return this;
	}
	/**
	 * Current statistics for PTS correction.<br>
	 * - decoding: maintained and used by libavcodec, not intended to be used by user apps<br>
	 * - encoding: unused<br>
	 * Number of incorrect PTS values so far
	 */
	@Field(167) 
	public long pts_correction_num_faulty_pts() {
		return this.io.getLongField(this, 167);
	}
	/**
	 * Current statistics for PTS correction.<br>
	 * - decoding: maintained and used by libavcodec, not intended to be used by user apps<br>
	 * - encoding: unused<br>
	 * Number of incorrect PTS values so far
	 */
	@Field(167) 
	public AVCodecContext pts_correction_num_faulty_pts(long pts_correction_num_faulty_pts) {
		this.io.setLongField(this, 167, pts_correction_num_faulty_pts);
		return this;
	}
	/** Number of incorrect DTS values so far */
	@Field(168) 
	public long pts_correction_num_faulty_dts() {
		return this.io.getLongField(this, 168);
	}
	/** Number of incorrect DTS values so far */
	@Field(168) 
	public AVCodecContext pts_correction_num_faulty_dts(long pts_correction_num_faulty_dts) {
		this.io.setLongField(this, 168, pts_correction_num_faulty_dts);
		return this;
	}
	/** PTS of the last frame */
	@Field(169) 
	public long pts_correction_last_pts() {
		return this.io.getLongField(this, 169);
	}
	/** PTS of the last frame */
	@Field(169) 
	public AVCodecContext pts_correction_last_pts(long pts_correction_last_pts) {
		this.io.setLongField(this, 169, pts_correction_last_pts);
		return this;
	}
	/** DTS of the last frame */
	@Field(170) 
	public long pts_correction_last_dts() {
		return this.io.getLongField(this, 170);
	}
	/** DTS of the last frame */
	@Field(170) 
	public AVCodecContext pts_correction_last_dts(long pts_correction_last_dts) {
		this.io.setLongField(this, 170, pts_correction_last_dts);
		return this;
	}
	/**
	 * Character encoding of the input subtitles file.<br>
	 * - decoding: set by user<br>
	 * - encoding: unused<br>
	 * C type : char*
	 */
	@Field(171) 
	public Pointer<Byte > sub_charenc() {
		return this.io.getPointerField(this, 171);
	}
	/**
	 * Character encoding of the input subtitles file.<br>
	 * - decoding: set by user<br>
	 * - encoding: unused<br>
	 * C type : char*
	 */
	@Field(171) 
	public AVCodecContext sub_charenc(Pointer<Byte > sub_charenc) {
		this.io.setPointerField(this, 171, sub_charenc);
		return this;
	}
	/**
	 * Subtitles character encoding mode. Formats or codecs might be adjusting<br>
	 * this setting (if they are doing the conversion themselves for instance).<br>
	 * - decoding: set by libavcodec<br>
	 * - encoding: unused
	 */
	@Field(172) 
	public int sub_charenc_mode() {
		return this.io.getIntField(this, 172);
	}
	/**
	 * Subtitles character encoding mode. Formats or codecs might be adjusting<br>
	 * this setting (if they are doing the conversion themselves for instance).<br>
	 * - decoding: set by libavcodec<br>
	 * - encoding: unused
	 */
	@Field(172) 
	public AVCodecContext sub_charenc_mode(int sub_charenc_mode) {
		this.io.setIntField(this, 172, sub_charenc_mode);
		return this;
	}
	/**
	 * Skip processing alpha if supported by codec.<br>
	 * Note that if the format uses pre-multiplied alpha (common with VP6,<br>
	 * and recommended due to better video quality/compression)<br>
	 * the image will look as if alpha-blended onto a black background.<br>
	 * However for formats that do not use pre-multiplied alpha<br>
	 * there might be serious artefacts (though e.g. libswscale currently<br>
	 * assumes pre-multiplied alpha anyway).<br>
	 * * - decoding: set by user<br>
	 * - encoding: unused
	 */
	@Field(173) 
	public int skip_alpha() {
		return this.io.getIntField(this, 173);
	}
	/**
	 * Skip processing alpha if supported by codec.<br>
	 * Note that if the format uses pre-multiplied alpha (common with VP6,<br>
	 * and recommended due to better video quality/compression)<br>
	 * the image will look as if alpha-blended onto a black background.<br>
	 * However for formats that do not use pre-multiplied alpha<br>
	 * there might be serious artefacts (though e.g. libswscale currently<br>
	 * assumes pre-multiplied alpha anyway).<br>
	 * * - decoding: set by user<br>
	 * - encoding: unused
	 */
	@Field(173) 
	public AVCodecContext skip_alpha(int skip_alpha) {
		this.io.setIntField(this, 173, skip_alpha);
		return this;
	}
	/**
	 * Number of samples to skip after a discontinuity<br>
	 * - decoding: unused<br>
	 * - encoding: set by libavcodec
	 */
	@Field(174) 
	public int seek_preroll() {
		return this.io.getIntField(this, 174);
	}
	/**
	 * Number of samples to skip after a discontinuity<br>
	 * - decoding: unused<br>
	 * - encoding: set by libavcodec
	 */
	@Field(174) 
	public AVCodecContext seek_preroll(int seek_preroll) {
		this.io.setIntField(this, 174, seek_preroll);
		return this;
	}
	/**
	 * debug motion vectors<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(175) 
	public int debug_mv() {
		return this.io.getIntField(this, 175);
	}
	/**
	 * debug motion vectors<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.
	 */
	@Field(175) 
	public AVCodecContext debug_mv(int debug_mv) {
		this.io.setIntField(this, 175, debug_mv);
		return this;
	}
	/**
	 * custom intra quantization matrix<br>
	 * - encoding: Set by user, can be NULL.<br>
	 * - decoding: unused.<br>
	 * C type : uint16_t*
	 */
	@Field(176) 
	public Pointer<Short > chroma_intra_matrix() {
		return this.io.getPointerField(this, 176);
	}
	/**
	 * custom intra quantization matrix<br>
	 * - encoding: Set by user, can be NULL.<br>
	 * - decoding: unused.<br>
	 * C type : uint16_t*
	 */
	@Field(176) 
	public AVCodecContext chroma_intra_matrix(Pointer<Short > chroma_intra_matrix) {
		this.io.setPointerField(this, 176, chroma_intra_matrix);
		return this;
	}
	/**
	 * dump format separator.<br>
	 * can be ", " or "\n      " or anything else<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.<br>
	 * C type : uint8_t*
	 */
	@Field(177) 
	public Pointer<Byte > dump_separator() {
		return this.io.getPointerField(this, 177);
	}
	/**
	 * dump format separator.<br>
	 * can be ", " or "\n      " or anything else<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by user.<br>
	 * C type : uint8_t*
	 */
	@Field(177) 
	public AVCodecContext dump_separator(Pointer<Byte > dump_separator) {
		this.io.setPointerField(this, 177, dump_separator);
		return this;
	}
	/**
	 * ',' separated list of allowed decoders.<br>
	 * If NULL then all are allowed<br>
	 * - encoding: unused<br>
	 * - decoding: set by user<br>
	 * C type : char*
	 */
	@Field(178) 
	public Pointer<Byte > codec_whitelist() {
		return this.io.getPointerField(this, 178);
	}
	/**
	 * ',' separated list of allowed decoders.<br>
	 * If NULL then all are allowed<br>
	 * - encoding: unused<br>
	 * - decoding: set by user<br>
	 * C type : char*
	 */
	@Field(178) 
	public AVCodecContext codec_whitelist(Pointer<Byte > codec_whitelist) {
		this.io.setPointerField(this, 178, codec_whitelist);
		return this;
	}
	/**
	 * Properties of the stream that gets decoded<br>
	 * - encoding: unused<br>
	 * - decoding: set by libavcodec
	 */
	@Field(179) 
	public int properties() {
		return this.io.getIntField(this, 179);
	}
	/**
	 * Properties of the stream that gets decoded<br>
	 * - encoding: unused<br>
	 * - decoding: set by libavcodec
	 */
	@Field(179) 
	public AVCodecContext properties(int properties) {
		this.io.setIntField(this, 179, properties);
		return this;
	}
	/**
	 * Additional data associated with the entire coded stream.<br>
	 * * - decoding: unused<br>
	 * - encoding: may be set by libavcodec after avcodec_open2().<br>
	 * C type : AVPacketSideData*
	 */
	@Field(180) 
	public Pointer<AVPacketSideData > coded_side_data() {
		return this.io.getPointerField(this, 180);
	}
	/**
	 * Additional data associated with the entire coded stream.<br>
	 * * - decoding: unused<br>
	 * - encoding: may be set by libavcodec after avcodec_open2().<br>
	 * C type : AVPacketSideData*
	 */
	@Field(180) 
	public AVCodecContext coded_side_data(Pointer<AVPacketSideData > coded_side_data) {
		this.io.setPointerField(this, 180, coded_side_data);
		return this;
	}
	@Field(181) 
	public int nb_coded_side_data() {
		return this.io.getIntField(this, 181);
	}
	@Field(181) 
	public AVCodecContext nb_coded_side_data(int nb_coded_side_data) {
		this.io.setIntField(this, 181, nb_coded_side_data);
		return this;
	}
	/**
	 * A reference to the AVHWFramesContext describing the input (for encoding)<br>
	 * or output (decoding) frames. The reference is set by the caller and<br>
	 * afterwards owned (and freed) by libavcodec - it should never be read by<br>
	 * the caller after being set.<br>
	 * * - decoding: This field should be set by the caller from the get_format()<br>
	 *             callback. The previous reference (if any) will always be<br>
	 *             unreffed by libavcodec before the get_format() call.<br>
	 * *             If the default get_buffer2() is used with a hwaccel pixel<br>
	 *             format, then this AVHWFramesContext will be used for<br>
	 *             allocating the frame buffers.<br>
	 * * - encoding: For hardware encoders configured to use a hwaccel pixel<br>
	 *             format, this field should be set by the caller to a reference<br>
	 *             to the AVHWFramesContext describing input frames.<br>
	 *             AVHWFramesContext.format must be equal to<br>
	 *             AVCodecContext.pix_fmt.<br>
	 * *             This field should be set before avcodec_open2() is called.<br>
	 * C type : AVBufferRef*
	 */
	@Field(182) 
	public Pointer<AVBufferRef > hw_frames_ctx() {
		return this.io.getPointerField(this, 182);
	}
	/**
	 * A reference to the AVHWFramesContext describing the input (for encoding)<br>
	 * or output (decoding) frames. The reference is set by the caller and<br>
	 * afterwards owned (and freed) by libavcodec - it should never be read by<br>
	 * the caller after being set.<br>
	 * * - decoding: This field should be set by the caller from the get_format()<br>
	 *             callback. The previous reference (if any) will always be<br>
	 *             unreffed by libavcodec before the get_format() call.<br>
	 * *             If the default get_buffer2() is used with a hwaccel pixel<br>
	 *             format, then this AVHWFramesContext will be used for<br>
	 *             allocating the frame buffers.<br>
	 * * - encoding: For hardware encoders configured to use a hwaccel pixel<br>
	 *             format, this field should be set by the caller to a reference<br>
	 *             to the AVHWFramesContext describing input frames.<br>
	 *             AVHWFramesContext.format must be equal to<br>
	 *             AVCodecContext.pix_fmt.<br>
	 * *             This field should be set before avcodec_open2() is called.<br>
	 * C type : AVBufferRef*
	 */
	@Field(182) 
	public AVCodecContext hw_frames_ctx(Pointer<AVBufferRef > hw_frames_ctx) {
		this.io.setPointerField(this, 182, hw_frames_ctx);
		return this;
	}
	/**
	 * Control the form of AVSubtitle.rects[N]->ass<br>
	 * - decoding: set by user<br>
	 * - encoding: unused
	 */
	@Field(183) 
	public int sub_text_format() {
		return this.io.getIntField(this, 183);
	}
	/**
	 * Control the form of AVSubtitle.rects[N]->ass<br>
	 * - decoding: set by user<br>
	 * - encoding: unused
	 */
	@Field(183) 
	public AVCodecContext sub_text_format(int sub_text_format) {
		this.io.setIntField(this, 183, sub_text_format);
		return this;
	}
	/**
	 * Audio only. The amount of padding (in samples) appended by the encoder to<br>
	 * the end of the audio. I.e. this number of decoded samples must be<br>
	 * discarded by the caller from the end of the stream to get the original<br>
	 * audio without any trailing padding.<br>
	 * * - decoding: unused<br>
	 * - encoding: unused
	 */
	@Field(184) 
	public int trailing_padding() {
		return this.io.getIntField(this, 184);
	}
	/**
	 * Audio only. The amount of padding (in samples) appended by the encoder to<br>
	 * the end of the audio. I.e. this number of decoded samples must be<br>
	 * discarded by the caller from the end of the stream to get the original<br>
	 * audio without any trailing padding.<br>
	 * * - decoding: unused<br>
	 * - encoding: unused
	 */
	@Field(184) 
	public AVCodecContext trailing_padding(int trailing_padding) {
		this.io.setIntField(this, 184, trailing_padding);
		return this;
	}
	/**
	 * The number of pixels per image to maximally accept.<br>
	 * * - decoding: set by user<br>
	 * - encoding: set by user
	 */
	@Field(185) 
	public long max_pixels() {
		return this.io.getLongField(this, 185);
	}
	/**
	 * The number of pixels per image to maximally accept.<br>
	 * * - decoding: set by user<br>
	 * - encoding: set by user
	 */
	@Field(185) 
	public AVCodecContext max_pixels(long max_pixels) {
		this.io.setLongField(this, 185, max_pixels);
		return this;
	}
	/**
	 * A reference to the AVHWDeviceContext describing the device which will<br>
	 * be used by a hardware encoder/decoder.  The reference is set by the<br>
	 * caller and afterwards owned (and freed) by libavcodec.<br>
	 * * This should be used if either the codec device does not require<br>
	 * hardware frames or any that are used are to be allocated internally by<br>
	 * libavcodec.  If the user wishes to supply any of the frames used as<br>
	 * encoder input or decoder output then hw_frames_ctx should be used<br>
	 * instead.  When hw_frames_ctx is set in get_format() for a decoder, this<br>
	 * field will be ignored while decoding the associated stream segment, but<br>
	 * may again be used on a following one after another get_format() call.<br>
	 * * For both encoders and decoders this field should be set before<br>
	 * avcodec_open2() is called and must not be written to thereafter.<br>
	 * * Note that some decoders may require this field to be set initially in<br>
	 * order to support hw_frames_ctx at all - in that case, all frames<br>
	 * contexts used must be created on the same device.<br>
	 * C type : AVBufferRef*
	 */
	@Field(186) 
	public Pointer<AVBufferRef > hw_device_ctx() {
		return this.io.getPointerField(this, 186);
	}
	/**
	 * A reference to the AVHWDeviceContext describing the device which will<br>
	 * be used by a hardware encoder/decoder.  The reference is set by the<br>
	 * caller and afterwards owned (and freed) by libavcodec.<br>
	 * * This should be used if either the codec device does not require<br>
	 * hardware frames or any that are used are to be allocated internally by<br>
	 * libavcodec.  If the user wishes to supply any of the frames used as<br>
	 * encoder input or decoder output then hw_frames_ctx should be used<br>
	 * instead.  When hw_frames_ctx is set in get_format() for a decoder, this<br>
	 * field will be ignored while decoding the associated stream segment, but<br>
	 * may again be used on a following one after another get_format() call.<br>
	 * * For both encoders and decoders this field should be set before<br>
	 * avcodec_open2() is called and must not be written to thereafter.<br>
	 * * Note that some decoders may require this field to be set initially in<br>
	 * order to support hw_frames_ctx at all - in that case, all frames<br>
	 * contexts used must be created on the same device.<br>
	 * C type : AVBufferRef*
	 */
	@Field(186) 
	public AVCodecContext hw_device_ctx(Pointer<AVBufferRef > hw_device_ctx) {
		this.io.setPointerField(this, 186, hw_device_ctx);
		return this;
	}
	/**
	 * Bit set of AV_HWACCEL_FLAG_* flags, which affect hardware accelerated<br>
	 * decoding (if active).<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user (either before avcodec_open2(), or in the<br>
	 *             AVCodecContext.get_format callback)
	 */
	@Field(187) 
	public int hwaccel_flags() {
		return this.io.getIntField(this, 187);
	}
	/**
	 * Bit set of AV_HWACCEL_FLAG_* flags, which affect hardware accelerated<br>
	 * decoding (if active).<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user (either before avcodec_open2(), or in the<br>
	 *             AVCodecContext.get_format callback)
	 */
	@Field(187) 
	public AVCodecContext hwaccel_flags(int hwaccel_flags) {
		this.io.setIntField(this, 187, hwaccel_flags);
		return this;
	}
	/**
	 * Video decoding only. Certain video codecs support cropping, meaning that<br>
	 * only a sub-rectangle of the decoded frame is intended for display.  This<br>
	 * option controls how cropping is handled by libavcodec.<br>
	 * * When set to 1 (the default), libavcodec will apply cropping internally.<br>
	 * I.e. it will modify the output frame width/height fields and offset the<br>
	 * data pointers (only by as much as possible while preserving alignment, or<br>
	 * by the full amount if the AV_CODEC_FLAG_UNALIGNED flag is set) so that<br>
	 * the frames output by the decoder refer only to the cropped area. The<br>
	 * crop_* fields of the output frames will be zero.<br>
	 * * When set to 0, the width/height fields of the output frames will be set<br>
	 * to the coded dimensions and the crop_* fields will describe the cropping<br>
	 * rectangle. Applying the cropping is left to the caller.<br>
	 * * @warning When hardware acceleration with opaque output frames is used,<br>
	 * libavcodec is unable to apply cropping from the top/left border.<br>
	 * * @note when this option is set to zero, the width/height fields of the<br>
	 * AVCodecContext and output AVFrames have different meanings. The codec<br>
	 * context fields store display dimensions (with the coded dimensions in<br>
	 * coded_width/height), while the frame fields store the coded dimensions<br>
	 * (with the display dimensions being determined by the crop_* fields).
	 */
	@Field(188) 
	public int apply_cropping() {
		return this.io.getIntField(this, 188);
	}
	/**
	 * Video decoding only. Certain video codecs support cropping, meaning that<br>
	 * only a sub-rectangle of the decoded frame is intended for display.  This<br>
	 * option controls how cropping is handled by libavcodec.<br>
	 * * When set to 1 (the default), libavcodec will apply cropping internally.<br>
	 * I.e. it will modify the output frame width/height fields and offset the<br>
	 * data pointers (only by as much as possible while preserving alignment, or<br>
	 * by the full amount if the AV_CODEC_FLAG_UNALIGNED flag is set) so that<br>
	 * the frames output by the decoder refer only to the cropped area. The<br>
	 * crop_* fields of the output frames will be zero.<br>
	 * * When set to 0, the width/height fields of the output frames will be set<br>
	 * to the coded dimensions and the crop_* fields will describe the cropping<br>
	 * rectangle. Applying the cropping is left to the caller.<br>
	 * * @warning When hardware acceleration with opaque output frames is used,<br>
	 * libavcodec is unable to apply cropping from the top/left border.<br>
	 * * @note when this option is set to zero, the width/height fields of the<br>
	 * AVCodecContext and output AVFrames have different meanings. The codec<br>
	 * context fields store display dimensions (with the coded dimensions in<br>
	 * coded_width/height), while the frame fields store the coded dimensions<br>
	 * (with the display dimensions being determined by the crop_* fields).
	 */
	@Field(188) 
	public AVCodecContext apply_cropping(int apply_cropping) {
		this.io.setIntField(this, 188, apply_cropping);
		return this;
	}
	/**
	 * Video decoding only.  Sets the number of extra hardware frames which<br>
	 * the decoder will allocate for use by the caller.  This must be set<br>
	 * before avcodec_open2() is called.<br>
	 * * Some hardware decoders require all frames that they will use for<br>
	 * output to be defined in advance before decoding starts.  For such<br>
	 * decoders, the hardware frame pool must therefore be of a fixed size.<br>
	 * The extra frames set here are on top of any number that the decoder<br>
	 * needs internally in order to operate normally (for example, frames<br>
	 * used as reference pictures).
	 */
	@Field(189) 
	public int extra_hw_frames() {
		return this.io.getIntField(this, 189);
	}
	/**
	 * Video decoding only.  Sets the number of extra hardware frames which<br>
	 * the decoder will allocate for use by the caller.  This must be set<br>
	 * before avcodec_open2() is called.<br>
	 * * Some hardware decoders require all frames that they will use for<br>
	 * output to be defined in advance before decoding starts.  For such<br>
	 * decoders, the hardware frame pool must therefore be of a fixed size.<br>
	 * The extra frames set here are on top of any number that the decoder<br>
	 * needs internally in order to operate normally (for example, frames<br>
	 * used as reference pictures).
	 */
	@Field(189) 
	public AVCodecContext extra_hw_frames(int extra_hw_frames) {
		this.io.setIntField(this, 189, extra_hw_frames);
		return this;
	}
	/** <i>native declaration : ./libavcodec/avcodec.h:2170</i> */
	public static abstract class draw_horiz_band_callback extends Callback<draw_horiz_band_callback > {
		public void apply(Pointer<AVCodecContext > s, Pointer<AVFrame > src, Pointer<Integer > offset, int y, int type, int height) {
			apply(Pointer.getPeer(s), Pointer.getPeer(src), Pointer.getPeer(offset), y, type, height);
		}
		public void apply(@Ptr long s, @Ptr long src, @Ptr long offset, int y, int type, int height) {
			apply(Pointer.pointerToAddress(s, AVCodecContext.class), Pointer.pointerToAddress(src, AVFrame.class), Pointer.pointerToAddress(offset, Integer.class), y, type, height);
		}
	};
	/** <i>native declaration : ./libavcodec/avcodec.h:2189</i> */
	public static abstract class get_buffer2_callback extends Callback<get_buffer2_callback > {
		public int apply(Pointer<AVCodecContext > s, Pointer<AVFrame > frame, int flags) {
			return apply(Pointer.getPeer(s), Pointer.getPeer(frame), flags);
		}
		public int apply(@Ptr long s, @Ptr long frame, int flags) {
			return apply(Pointer.pointerToAddress(s, AVCodecContext.class), Pointer.pointerToAddress(frame, AVFrame.class), flags);
		}
	};
	/** <i>native declaration : ./libavcodec/avcodec.h:2190</i> */
	public static abstract class rtp_callback_callback extends Callback<rtp_callback_callback > {
		public void apply(Pointer<AVCodecContext > avctx, Pointer<? > data, int size, int mb_nb) {
			apply(Pointer.getPeer(avctx), Pointer.getPeer(data), size, mb_nb);
		}
		public void apply(@Ptr long avctx, @Ptr long data, int size, int mb_nb) {
			apply(Pointer.pointerToAddress(avctx, AVCodecContext.class), Pointer.pointerToAddress(data), size, mb_nb);
		}
	};
	/** <i>native declaration : ./libavcodec/avcodec.h:2191</i> */
	public static abstract class execute_callback_func_callback extends Callback<execute_callback_func_callback > {
		public int apply(Pointer<AVCodecContext > c2, Pointer<? > arg) {
			return apply(Pointer.getPeer(c2), Pointer.getPeer(arg));
		}
		public int apply(@Ptr long c2, @Ptr long arg) {
			return apply(Pointer.pointerToAddress(c2, AVCodecContext.class), Pointer.pointerToAddress(arg));
		}
	};
	/** <i>native declaration : ./libavcodec/avcodec.h:2192</i> */
	public static abstract class execute_callback extends Callback<execute_callback > {
		public int apply(Pointer<AVCodecContext > c, Pointer<AVCodecContext.execute_callback_func_callback > func, Pointer<? > arg2, Pointer<Integer > ret, int count, int size) {
			return apply(Pointer.getPeer(c), Pointer.getPeer(func), Pointer.getPeer(arg2), Pointer.getPeer(ret), count, size);
		}
		public int apply(@Ptr long c, @Ptr long func, @Ptr long arg2, @Ptr long ret, int count, int size) {
			return apply(Pointer.pointerToAddress(c, AVCodecContext.class), Pointer.pointerToAddress(func, AVCodecContext.execute_callback_func_callback.class), Pointer.pointerToAddress(arg2), Pointer.pointerToAddress(ret, Integer.class), count, size);
		}
	};
	/** <i>native declaration : ./libavcodec/avcodec.h:2193</i> */
	public static abstract class execute2_callback_func_callback extends Callback<execute2_callback_func_callback > {
		public int apply(Pointer<AVCodecContext > c2, Pointer<? > arg, int jobnr, int threadnr) {
			return apply(Pointer.getPeer(c2), Pointer.getPeer(arg), jobnr, threadnr);
		}
		public int apply(@Ptr long c2, @Ptr long arg, int jobnr, int threadnr) {
			return apply(Pointer.pointerToAddress(c2, AVCodecContext.class), Pointer.pointerToAddress(arg), jobnr, threadnr);
		}
	};
	/** <i>native declaration : ./libavcodec/avcodec.h:2194</i> */
	public static abstract class execute2_callback extends Callback<execute2_callback > {
		public int apply(Pointer<AVCodecContext > c, Pointer<AVCodecContext.execute2_callback_func_callback > func, Pointer<? > arg2, Pointer<Integer > ret, int count) {
			return apply(Pointer.getPeer(c), Pointer.getPeer(func), Pointer.getPeer(arg2), Pointer.getPeer(ret), count);
		}
		public int apply(@Ptr long c, @Ptr long func, @Ptr long arg2, @Ptr long ret, int count) {
			return apply(Pointer.pointerToAddress(c, AVCodecContext.class), Pointer.pointerToAddress(func, AVCodecContext.execute2_callback_func_callback.class), Pointer.pointerToAddress(arg2), Pointer.pointerToAddress(ret, Integer.class), count);
		}
	};
	@Struct(customizer=AlignmentCustomizer.class)
	public AVCodecContext() {
		super();
	}
	@Struct(customizer=AlignmentCustomizer.class)
	public AVCodecContext(Pointer pointer) {
		super(pointer);
	}
}
